{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib._util.visualplot as vp\n",
    "\n",
    "# Pre-processing\n",
    "from lib._class.DFBoxCoxTransformer import DFBoxCoxTransformer\n",
    "from lib._class.DFDTypeTransformer import DFDTypeTransformer\n",
    "\n",
    "# Feature encoding\n",
    "from lib._class.DFOneHotEncoder import DFOneHotEncoder\n",
    "from lib._class.DFBinaryEncoder import DFBinaryEncoder\n",
    "\n",
    "# Feature scaling\n",
    "from lib._class.DFStandardScaler import DFStandardScaler\n",
    "from lib._class.DFMinMaxScaler import DFMinMaxScaler\n",
    "\n",
    "# Feature extraction\n",
    "from lib._class.DFPCA import DFPCA\n",
    "from lib._class.DFMCA import DFMCA\n",
    "from lib._class.DFIvis import DFIvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH_DATA = 'resources/data/'\n",
    "OUT_PATH_GRAPH   = 'resources/output/graph/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Data Loading\n",
    "- Reference: https://www.kaggle.com/c/allstate-claims-severity/data\n",
    "- Each row in this dataset represents an insurance claim.\n",
    "- Variables prefaced with 'cat' are categorical, while those prefaced with 'cont' are continuous.\n",
    "- You must predict the value for the 'loss' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    df_chunks = pd.read_csv(f'{SOURCE_PATH_DATA}{filename}', sep=',', chunksize=50_000,\n",
    "                            nrows=25_000)\n",
    "    return pd.concat(df_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data('train.csv')\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['loss'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification target\n",
    "train_df['target'] = np.where(train_df['loss'] >= 10_000, 1, 0)\n",
    "\n",
    "vp.value_count(train_df, 'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.histogram(train_df.select_dtypes(include='number'),\n",
    "             bin_algo='count',\n",
    "             max_col=4,\n",
    "             title='Phase 1 - Histogram - Numerical',\n",
    "             out_path=OUT_PATH_GRAPH,\n",
    "             layout_kwargs={'height': 1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.histogram(train_df.select_dtypes(include='object'),\n",
    "             bin_algo='count',\n",
    "             max_col=4,\n",
    "             title='Phase 1 - Histogram - Categorical',\n",
    "             out_path=OUT_PATH_GRAPH,\n",
    "             layout_kwargs={'height': 5000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 - Data Preparation\n",
    "- Handle skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_transformer = DFBoxCoxTransformer(columns=['loss'])\n",
    "train_df = boxcox_transformer.fit_transform(train_df)\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_transformer.stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 - Data Preparation\n",
    "- Feature encoding\n",
    "- Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[[x for x in train_df.columns if x not in ['id', 'loss', 'target']]].copy()\n",
    "y_regress = train_df['loss'].copy()\n",
    "y_classif = train_df['target'].copy()\n",
    "\n",
    "X.shape, y_regress.shape, y_classif.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature encoding (low cardinality)\n",
    "low_cardinalities = [x for x in X.select_dtypes(include='object').columns if len(X[x].unique()) < 10]\n",
    "onehot_encoder    = DFOneHotEncoder(columns=low_cardinalities, dtype='byte', drop='first')\n",
    "\n",
    "# Feature encoding (high cardinality)\n",
    "high_cardinalities = [x for x in X.select_dtypes(include='object').columns if x not in low_cardinalities]\n",
    "binary_encoder     = DFBinaryEncoder(columns=high_cardinalities, drop_invariant=True)\n",
    "\n",
    "# Feature scaling\n",
    "standard_scaler = DFStandardScaler(columns=X.select_dtypes(include='number').columns)\n",
    "\n",
    "steps = [\n",
    "    ('onehot_encoder', onehot_encoder),\n",
    "    ('binary_encoder', binary_encoder),\n",
    "    ('standard_scaler', standard_scaler),\n",
    "]\n",
    "X = Pipeline(steps).fit_transform(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4 - Data Preparation\n",
    "- Feature extraction (PCA + MCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remain all dimensions to evaluate N dimensions needed for local PCA & MCA\n",
    "dtype_transformer = DFDTypeTransformer(dtype_dict={\n",
    "    'str': X.select_dtypes(include='int8').columns\n",
    "})\n",
    "\n",
    "numerics  = X.select_dtypes(include='float').columns\n",
    "local_pca = DFPCA(columns=numerics,\n",
    "                  n_components=len(numerics),\n",
    "                  rescale_with_mean=False, rescale_with_std=False)\n",
    "\n",
    "categories = X.select_dtypes(include='int8').columns\n",
    "local_mca  = DFMCA(columns=categories,\n",
    "                   n_components=X[categories].apply(lambda x: len(x.unique())).sum())\n",
    "\n",
    "steps = [\n",
    "    ('dtype_transformer', dtype_transformer),\n",
    "    ('local_pca', local_pca),\n",
    "    ('local_mca', local_mca),\n",
    "]\n",
    "pipeline = Pipeline(steps, verbose=True).fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(local_pca.stat_df,\n",
    "        xy_tuples=[('dimension', x) for x in ['explained_inertia', 'cumsum_explained_inertia']],\n",
    "        title='Phase 4 - Inertia - Local PCA',\n",
    "        out_path=OUT_PATH_GRAPH,\n",
    "        scattergl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(local_mca.stat_df,\n",
    "        xy_tuples=[('dimension', x) for x in ['explained_inertia', 'cumsum_explained_inertia']],\n",
    "        title='Phase 4 - Inertia - Local MCA',\n",
    "        out_path=OUT_PATH_GRAPH,\n",
    "        scattergl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remain N dimensions to explain 100% inertia\n",
    "local_pca = DFPCA(columns=numerics,\n",
    "                  n_components=14,\n",
    "                  rescale_with_mean=False, rescale_with_std=False)\n",
    "\n",
    "local_mca  = DFMCA(columns=categories,\n",
    "                   n_components=246)\n",
    "\n",
    "steps = [\n",
    "    ('dtype_transformer', dtype_transformer),\n",
    "    ('local_pca', local_pca),\n",
    "    ('local_mca', local_mca),\n",
    "]\n",
    "pca_df = Pipeline(steps, verbose=True).fit_transform(X)\n",
    "\n",
    "pca_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remain all dimensions to evaluate N dimensions needed for global PCA\n",
    "global_standard_scaler = DFStandardScaler()\n",
    "global_pca             = DFPCA(n_components=pca_df.shape[1],\n",
    "                               rescale_with_mean=False, rescale_with_std=False)\n",
    "\n",
    "steps = [\n",
    "    ('global_standard_scaler', global_standard_scaler),\n",
    "    ('global_pca', global_pca)\n",
    "]\n",
    "pipeline = Pipeline(steps, verbose=True).fit(pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(global_pca.stat_df,\n",
    "        xy_tuples=[('dimension', x) for x in ['explained_inertia', 'cumsum_explained_inertia']],\n",
    "        title='Phase 4 - Inertia - Global PCA',\n",
    "        out_path=OUT_PATH_GRAPH,\n",
    "        scattergl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remain N dimensions to explain 90% inertia\n",
    "global_pca = DFPCA(n_components=225,\n",
    "                   rescale_with_mean=False, rescale_with_std=False)\n",
    "\n",
    "steps = [\n",
    "    ('global_standard_scaler', global_standard_scaler),\n",
    "    ('global_pca', global_pca)\n",
    "]\n",
    "pca_df = Pipeline(steps, verbose=True).fit_transform(pca_df)\n",
    "\n",
    "pca_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.scatter(pd.concat([pca_df, y_regress], axis=1),\n",
    "           xy_tuples=[('pca_0', x) for x in [x for x in pca_df.columns if x != 'pca_0'][:4]],\n",
    "           color='loss',\n",
    "           title='Phase 4 - Scatter - PCA - Regression',\n",
    "           max_col=2,\n",
    "           out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([pca_df, y_classif], axis=1)\n",
    "tmp_df['target'] = tmp_df['target'].astype(str)\n",
    "\n",
    "vp.scatter(tmp_df,\n",
    "           xy_tuples=[('pca_0', x) for x in [x for x in pca_df.columns if x != 'pca_0'][:4]],\n",
    "           color='target',\n",
    "           title='Phase 4 - Scatter - PCA - Classification',\n",
    "           max_col=2,\n",
    "           out_path=OUT_PATH_GRAPH)\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5 - Data Preparation\n",
    "- Feature extraction (Ivis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unsupervised ivis\n",
    "minmax_scaler = DFMinMaxScaler()\n",
    "ivis          = DFIvis(embedding_dims=5,\n",
    "                       k=150, n_epochs_without_progress=10, model='szubert')\n",
    "\n",
    "steps = [\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "    ('ivis', ivis),\n",
    "]\n",
    "ivis_df = Pipeline(steps, verbose=True).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(ivis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.scatter(pd.concat([ivis_df, y_regress], axis=1),\n",
    "           xy_tuples=[('ivis_0', x) for x in [x for x in ivis_df.columns if x != 'ivis_0'][:4]],\n",
    "           color='loss',\n",
    "           title='Phase 5 - Scatter - Unsupervised Ivis - Regression',\n",
    "           max_col=2,\n",
    "           out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([ivis_df, y_classif], axis=1)\n",
    "tmp_df['target'] = tmp_df['target'].astype(str)\n",
    "\n",
    "vp.scatter(tmp_df,\n",
    "           xy_tuples=[('ivis_0', x) for x in [x for x in ivis_df.columns if x != 'ivis_0'][:4]],\n",
    "           color='target',\n",
    "           title='Phase 5 - Scatter - Unsupervised Ivis - Classification',\n",
    "           max_col=2,\n",
    "           out_path=OUT_PATH_GRAPH)\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ivis (regression)\n",
    "minmax_scaler = DFMinMaxScaler()\n",
    "ivis          = DFIvis(embedding_dims=5,\n",
    "                       k=150, n_epochs_without_progress=10, model='szubert',\n",
    "                       supervision_weight=1, supervision_metric='mean_squared_error', distance='softmax_ratio')\n",
    "\n",
    "steps = [\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "    ('ivis', ivis),\n",
    "]\n",
    "ivis_df = Pipeline(steps, verbose=True).fit_transform(X, y_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(ivis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.scatter(pd.concat([ivis_df, y_regress], axis=1),\n",
    "           xy_tuples=[('ivis_0', x) for x in [x for x in ivis_df.columns if x != 'ivis_0'][:4]],\n",
    "           color='loss',\n",
    "           title='Phase 5 - Scatter - Ivis - Regression',\n",
    "           max_col=2,\n",
    "           out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ivis (classification)\n",
    "minmax_scaler = DFMinMaxScaler()\n",
    "ivis          = DFIvis(embedding_dims=5,\n",
    "                       k=150, n_epochs_without_progress=10, model='szubert',\n",
    "                       supervision_weight=1, supervision_metric='binary_crossentropy', distance='softmax_ratio_pn')\n",
    "\n",
    "steps = [\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "    ('ivis', ivis),\n",
    "]\n",
    "ivis_df = Pipeline(steps, verbose=True).fit_transform(X, y_classif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([ivis_df, y_classif], axis=1)\n",
    "tmp_df['target'] = tmp_df['target'].astype(str)\n",
    "\n",
    "vp.scatter(tmp_df,\n",
    "           xy_tuples=[('ivis_0', x) for x in [x for x in ivis_df.columns if x != 'ivis_0'][:4]],\n",
    "           color='target',\n",
    "           title='Phase 5 - Scatter - Ivis - Classification',\n",
    "           max_col=2,\n",
    "           out_path=OUT_PATH_GRAPH)\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
