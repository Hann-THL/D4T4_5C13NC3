{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referance: https://www.youtube.com/watch?v=HdlDYng8g9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib._util.visualplot as vp\n",
    "import lib._util.mlpipe as mlpipe\n",
    "\n",
    "# Feature scaling\n",
    "from lib._class.DFStandardScaler import DFStandardScaler\n",
    "from lib._class.DFRobustScaler import DFRobustScaler\n",
    "from lib._class.DFMinMaxScaler import DFMinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB, ComplementNB, GaussianNB, MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, StackingClassifier\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "# Plotly\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH_GRAPH = 'resources/output/graph/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data_dict = datasets.load_iris()\n",
    "    \n",
    "    X = pd.DataFrame(\n",
    "        data_dict['data'],\n",
    "        columns=data_dict['feature_names']\n",
    "    )\n",
    "    y = pd.Series(\n",
    "        data_dict['target'],\n",
    "        name='target'\n",
    "    )\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data()\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "vp.value_count(y.to_frame(), 'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Hyperparameter (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(\n",
    "    estimator=SVC(random_state=0, probability=True),\n",
    "    param_grid={\n",
    "        'C': [1, 10, 20, 30, 40, 50],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "    },\n",
    "    scoring=['f1_macro', 'roc_auc_ovr', 'balanced_accuracy'],\n",
    "    refit='f1_macro',\n",
    "    cv=StratifiedKFold(n_splits=10),\n",
    "    n_jobs=-1,\n",
    "    verbose=10,\n",
    ")\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(search.cv_results_)\n",
    "result_df[[\n",
    "    'params',\n",
    "    'mean_test_f1_macro', 'rank_test_f1_macro',\n",
    "    'mean_test_roc_auc_ovr', 'rank_test_roc_auc_ovr',\n",
    "    'mean_test_balanced_accuracy', 'rank_test_balanced_accuracy'\n",
    "]].sort_values(by=['mean_test_f1_macro', 'mean_test_roc_auc_ovr', 'mean_test_balanced_accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(**search.best_params_, random_state=0, probability=True)\n",
    "svc.fit(X, y)\n",
    "\n",
    "mlpipe.eval_classif(\n",
    "    y,\n",
    "    svc.predict(X),\n",
    "    y_prob=svc.predict_proba(X),\n",
    "    multi_class='ovr'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Hyperparameter (RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(\n",
    "    estimator=SVC(random_state=0, probability=True),\n",
    "    param_distributions={\n",
    "        'C': [1, 10, 20, 30, 40, 50],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "    },\n",
    "    scoring=['f1_macro', 'roc_auc_ovr', 'balanced_accuracy'],\n",
    "    refit='f1_macro',\n",
    "    cv=StratifiedKFold(n_splits=10),\n",
    "    n_jobs=-1,\n",
    "    verbose=10,\n",
    "    n_iter=100,\n",
    "    random_state=0\n",
    ")\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(search.cv_results_)\n",
    "result_df[[\n",
    "    'params',\n",
    "    'mean_test_f1_macro', 'rank_test_f1_macro',\n",
    "    'mean_test_roc_auc_ovr', 'rank_test_roc_auc_ovr',\n",
    "    'mean_test_balanced_accuracy', 'rank_test_balanced_accuracy'\n",
    "]].sort_values(by=['mean_test_f1_macro', 'mean_test_roc_auc_ovr', 'mean_test_balanced_accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(**search.best_params_, random_state=0, probability=True)\n",
    "svc.fit(X, y)\n",
    "\n",
    "mlpipe.eval_classif(\n",
    "    y,\n",
    "    svc.predict(X),\n",
    "    y_prob=svc.predict_proba(X),\n",
    "    multi_class='ovr'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = mlpipe.dataset_split(X, y, test_size=.2, stratify=y, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "print('Train Dataset:')\n",
    "vp.value_count(y_train.to_frame(), 'target')\n",
    "print('\\nTest Dataset:')\n",
    "vp.value_count(y_test.to_frame(), 'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimators():\n",
    "    kwargs1 = {'random_state': 0, 'n_jobs': -1}\n",
    "    kwargs2 = {'n_jobs': -1}\n",
    "    kwargs3 = {'random_state': 0}\n",
    "    \n",
    "    estimators = [\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            KNeighborsClassifier(**kwargs2)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            CalibratedClassifierCV(OneVsRestClassifier(LinearSVC(**kwargs3), **kwargs2))\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            OneVsRestClassifier(NuSVC(**kwargs3, probability=True), **kwargs2)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            OneVsRestClassifier(SVC(**kwargs3, probability=True), **kwargs2)\n",
    "        ),\n",
    "        XGBClassifier(**kwargs1),\n",
    "        LGBMClassifier(**kwargs1),\n",
    "        GradientBoostingClassifier(**kwargs3),\n",
    "        ExtraTreesClassifier(**kwargs1),\n",
    "        RandomForestClassifier(**kwargs1),\n",
    "        DecisionTreeClassifier(**kwargs3),\n",
    "        ExtraTreeClassifier(**kwargs3),\n",
    "        make_pipeline(\n",
    "            DFRobustScaler(),\n",
    "            DFMinMaxScaler(),\n",
    "            LogisticRegression(**kwargs1)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFRobustScaler(),\n",
    "            DFMinMaxScaler(),\n",
    "            CalibratedClassifierCV(PassiveAggressiveClassifier(**kwargs1))\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFRobustScaler(),\n",
    "            DFMinMaxScaler(),\n",
    "            CalibratedClassifierCV(Perceptron(**kwargs1))\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            CalibratedClassifierCV(RidgeClassifier(**kwargs3))\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFRobustScaler(),\n",
    "            DFMinMaxScaler(),\n",
    "            SGDClassifier(**kwargs1)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            LinearDiscriminantAnalysis()\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            QuadraticDiscriminantAnalysis()\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFRobustScaler(),\n",
    "            DFMinMaxScaler(),\n",
    "            MLPClassifier(**kwargs3)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            GaussianProcessClassifier(**kwargs1)\n",
    "        ),\n",
    "        BernoulliNB(),\n",
    "        CategoricalNB(),\n",
    "        ComplementNB(),\n",
    "        GaussianNB(),\n",
    "        MultinomialNB(),\n",
    "        DummyClassifier(**kwargs3),\n",
    "    ]\n",
    "    \n",
    "    def model_name(model):\n",
    "        name = model.__class__.__name__\n",
    "        if name == 'RandomForestClassifier':\n",
    "            return name\n",
    "\n",
    "        if hasattr(model, 'estimator'):\n",
    "            return model_name(model.estimator)\n",
    "\n",
    "        elif hasattr(model, 'base_estimator'):\n",
    "            return model_name(model.base_estimator)\n",
    "\n",
    "        return name\n",
    "    \n",
    "    return [(model_name(x.steps[-1][1]) if type(x) == Pipeline else model_name(x), x) for x in estimators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(estimator, X, y):\n",
    "    return cross_validate(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        scoring=['f1_macro', 'roc_auc_ovr', 'balanced_accuracy'],\n",
    "        cv=StratifiedKFold(10),\n",
    "        verbose=10,\n",
    "        n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_dict = {\n",
    "    'model':             [],\n",
    "    'f1_macro':          [],\n",
    "    'roc_auc_ovr':       [],\n",
    "    'balanced_accuracy': [],\n",
    "}\n",
    "\n",
    "for name, estimator in get_estimators():\n",
    "    print(name)\n",
    "    cv_dict = cross_validation(estimator, X_train, y_train)\n",
    "    \n",
    "    eval_dict['model'].append(name)\n",
    "    eval_dict['f1_macro'].append(cv_dict['test_f1_macro'])\n",
    "    eval_dict['roc_auc_ovr'].append(cv_dict['test_roc_auc_ovr'])\n",
    "    eval_dict['balanced_accuracy'].append(cv_dict['test_balanced_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(eval_dict)\n",
    "for cv_score in eval_dict.keys():\n",
    "    if cv_score == 'model':\n",
    "        continue\n",
    "    \n",
    "    eval_df[f'mean_{cv_score}'] = eval_df[cv_score].apply(np.mean)\n",
    "    eval_df[f'std_{cv_score}']  = eval_df[cv_score].apply(np.std)\n",
    "\n",
    "eval_dfs = []\n",
    "for index in eval_df.index:\n",
    "    eval_dfs.append(\n",
    "        pd.DataFrame({\n",
    "            'model': eval_df.at[index, 'model'],\n",
    "            'f1_macro': eval_df.at[index, 'f1_macro'],\n",
    "            'balanced_accuracy': eval_df.at[index, 'balanced_accuracy'],\n",
    "        })\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.box(\n",
    "    pd.concat(eval_dfs, axis=0),\n",
    "    color='model',\n",
    "    max_col=2,\n",
    "    title='Classifier - Baseline',\n",
    "    out_path=OUT_PATH_GRAPH,\n",
    "    layout_kwargs={'showlegend': False},\n",
    "    box_kwargs={\n",
    "        'boxmean': 'sd',\n",
    "        'boxpoints': False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kneighbors_params = {\n",
    "    'kneighborsclassifier__n_neighbors': [3, 5, 10, 25, 50, 100],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "    'kneighborsclassifier__metric': ['euclidean', 'manhattan'],\n",
    "}\n",
    "linearsvc_params = {\n",
    "    'calibratedclassifiercv__base_estimator__estimator__C': [.001, .01, .1, 1, 10, 100, 1000],\n",
    "    'calibratedclassifiercv__base_estimator__estimator__fit_intercept': [True, False],\n",
    "    'calibratedclassifiercv__base_estimator__estimator__max_iter': [1000],\n",
    "}\n",
    "nusvc_params = {\n",
    "    'onevsrestclassifier__estimator__nu': np.linspace(.1, 1, 10),\n",
    "    'onevsrestclassifier__estimator__probability': [True],\n",
    "    'onevsrestclassifier__estimator__max_iter': [1000],\n",
    "    'onevsrestclassifier__estimator__decision_function_shape': ['ovr'],\n",
    "    'onevsrestclassifier__estimator__break_ties': [True, False],\n",
    "}\n",
    "svc_params = {\n",
    "    'onevsrestclassifier__estimator__probability': [True],\n",
    "    'onevsrestclassifier__estimator__max_iter': [1000],\n",
    "    'onevsrestclassifier__estimator__decision_function_shape': ['ovr'],\n",
    "    'onevsrestclassifier__estimator__break_ties': [True, False],\n",
    "}\n",
    "tree_params = {\n",
    "    'max_depth': [None, 3, 5, 7, 10, 15],\n",
    "    'min_samples_split': np.linspace(.1, 1, 10),\n",
    "    'min_samples_leaf': np.linspace(.1, .5, 5),\n",
    "    'max_features': ['sqrt', 'log2'] + list(np.linspace(.5, 1, 6)),\n",
    "}\n",
    "logistic_params = {\n",
    "    'logisticregression__C': [.001, .01, .1, 1, 10, 100, 1000],\n",
    "    'logisticregression__fit_intercept': [True, False],\n",
    "    'logisticregression__max_iter': [1000],\n",
    "    'logisticregression__multi_class': ['auto'],\n",
    "}\n",
    "sgd_params = {\n",
    "#     'sgdclassifier__loss': ['hinge', 'modified_huber', 'squared_hinge',\n",
    "#                             'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'sgdclassifier__loss': ['modified_huber'], # Availble for probabilities\n",
    "    'sgdclassifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'sgdclassifier__l1_ratio': np.linspace(.1, .9, 9),\n",
    "    'sgdclassifier__fit_intercept': [True, False],\n",
    "    'sgdclassifier__max_iter': [1000],\n",
    "    'sgdclassifier__average': [True, False],\n",
    "}\n",
    "mlp_params = {\n",
    "    'mlpclassifier__hidden_layer_sizes': [(100,), (32, 64, 128) , (128, 64, 32)],\n",
    "    'mlpclassifier__activation': ['relu'],\n",
    "    'mlpclassifier__max_iter': [1000],\n",
    "}\n",
    "naivebayes_params = {\n",
    "    'alpha': np.linspace(0, 1, 11),\n",
    "    'fit_prior': [True, False],\n",
    "}\n",
    "lgb_params = {\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss', 'rf'],\n",
    "    'learning_rate': [.1, .01],\n",
    "    'objective': ['binary'],\n",
    "    'colsample_bytree': np.linspace(.5, 1, 6),\n",
    "    'reg_alpha': np.linspace(0, 1, 11),\n",
    "    'reg_lambda': np.linspace(0, 1, 11),\n",
    "}\n",
    "\n",
    "\n",
    "search_params = [\n",
    "    # KNeighborsClassifier\n",
    "    [\n",
    "        {\n",
    "            **kneighbors_params,\n",
    "            'kneighborsclassifier__algorithm': ['ball_tree', 'kd_tree'],\n",
    "            'kneighborsclassifier__leaf_size': [3, 30, 300, 3000],\n",
    "        },\n",
    "        {\n",
    "            **kneighbors_params,\n",
    "            'kneighborsclassifier__algorithm': ['brute'],\n",
    "        }\n",
    "    ],\n",
    "    # LinearSVC\n",
    "    [\n",
    "        {\n",
    "            **linearsvc_params,\n",
    "            'calibratedclassifiercv__base_estimator__estimator__multi_class': ['ovr'],\n",
    "            'calibratedclassifiercv__base_estimator__estimator__penalty': ['l2'],\n",
    "            'calibratedclassifiercv__base_estimator__estimator__loss': ['squared_hinge'],\n",
    "            'calibratedclassifiercv__base_estimator__estimator__dual': [True, False],\n",
    "        },\n",
    "        {\n",
    "            **linearsvc_params,\n",
    "            'calibratedclassifiercv__base_estimator__estimator__multi_class': ['ovr'],\n",
    "            'calibratedclassifiercv__base_estimator__estimator__penalty': ['l2'],\n",
    "            'calibratedclassifiercv__base_estimator__estimator__loss': ['hinge'],\n",
    "            'calibratedclassifiercv__base_estimator__estimator__dual': [True],\n",
    "        },\n",
    "        {\n",
    "            **linearsvc_params,\n",
    "            'calibratedclassifiercv__base_estimator__estimator__multi_class': ['ovr'],\n",
    "            'calibratedclassifiercv__base_estimator__estimator__penalty': ['l1'],\n",
    "            'calibratedclassifiercv__base_estimator__estimator__loss': ['squared_hinge'],\n",
    "            'calibratedclassifiercv__base_estimator__estimator__dual': [False],\n",
    "        },\n",
    "        {\n",
    "            **linearsvc_params,\n",
    "            'calibratedclassifiercv__base_estimator__estimator__multi_class': ['crammer_singer'],\n",
    "        }\n",
    "    ],\n",
    "    # NuSVC\n",
    "    [\n",
    "        {\n",
    "            **nusvc_params,\n",
    "            'onevsrestclassifier__estimator__kernel': ['linear', 'precomputed'],\n",
    "            \n",
    "        },\n",
    "        {\n",
    "            **nusvc_params,\n",
    "            'onevsrestclassifier__estimator__kernel': ['rbf', 'sigmoid'],\n",
    "            'onevsrestclassifier__estimator__gamma': [.001, .01, .1, 1, 10, 100, 1000, 'scale', 'auto'],\n",
    "        },\n",
    "        {\n",
    "            **nusvc_params,\n",
    "            'onevsrestclassifier__estimator__kernel': ['poly'],\n",
    "            'onevsrestclassifier__estimator__gamma': [.001, .01, .1, 1, 10, 100, 1000, 'scale', 'auto'],\n",
    "            'onevsrestclassifier__estimator__degree': [.003, .03, .3, 3, 30, 300, 3000],\n",
    "        }\n",
    "    ],\n",
    "    # SVC\n",
    "    [\n",
    "        {\n",
    "            **svc_params,\n",
    "            'onevsrestclassifier__estimator__kernel': ['linear', 'precomputed'],\n",
    "        },\n",
    "        {\n",
    "            **svc_params,\n",
    "            'onevsrestclassifier__estimator__kernel': ['rbf', 'sigmoid'],\n",
    "            'onevsrestclassifier__estimator__gamma': [.001, .01, .1, 1, 10, 100, 1000, 'scale', 'auto'],\n",
    "        },\n",
    "        {\n",
    "            **svc_params,\n",
    "            'onevsrestclassifier__estimator__kernel': ['poly'],\n",
    "            'onevsrestclassifier__estimator__gamma': [.001, .01, .1, 1, 10, 100, 1000, 'scale', 'auto'],\n",
    "            'onevsrestclassifier__estimator__degree': [.003, .03, .3, 3, 30, 300, 3000],\n",
    "        }\n",
    "    ],\n",
    "    # XGBClassifier\n",
    "    [\n",
    "        {\n",
    "            'n_estimators': [25, 50, 100, 500, 1000],\n",
    "            'max_depth': [None, 3, 5, 7, 10, 15],\n",
    "            'learning_rate': [.1, .01],\n",
    "            'objective': ['reg:logistic', 'binary:logistic'],\n",
    "            'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "            'subsample': [.8],\n",
    "            'colsample_bytree': np.linspace(.5, 1, 6),\n",
    "            'reg_alpha': np.linspace(0, 1, 11),\n",
    "            'reg_lambda': np.linspace(0, 1, 11),\n",
    "        }\n",
    "    ],\n",
    "    # LGBMClassifier\n",
    "    [\n",
    "        {\n",
    "            **lgb_params,\n",
    "            'num_leaves': [31],\n",
    "            'max_depth': [-1],\n",
    "        },\n",
    "        {\n",
    "            **lgb_params,\n",
    "            'num_leaves': [9],\n",
    "            'max_depth': [3],\n",
    "        },\n",
    "        {\n",
    "            **lgb_params,\n",
    "            'num_leaves': [25],\n",
    "            'max_depth': [5],\n",
    "        },\n",
    "        {\n",
    "            **lgb_params,\n",
    "            'num_leaves': [49],\n",
    "            'max_depth': [7],\n",
    "        },\n",
    "        {\n",
    "            **lgb_params,\n",
    "            'num_leaves': [100],\n",
    "            'max_depth': [10],\n",
    "        },\n",
    "        {\n",
    "            **lgb_params,\n",
    "            'num_leaves': [225],\n",
    "            'max_depth': [15],\n",
    "        }\n",
    "    ],\n",
    "    # GradientBoostingClassifier\n",
    "    [\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "            'n_estimators': [25, 50, 100, 500, 1000],\n",
    "            'loss': ['deviance', 'exponential'],\n",
    "            'learning_rate': [.1, .01],\n",
    "            'subsample': np.linspace(.5, 1, 6),\n",
    "        }\n",
    "    ],\n",
    "    # ExtraTreesClassifier\n",
    "    [\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'n_estimators': [25, 50, 100, 500, 1000],\n",
    "            'oob_score': [True, False],\n",
    "            'bootstrap': [False],\n",
    "        },\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'n_estimators': [25, 50, 100, 500, 1000],\n",
    "            'oob_score': [True, False],\n",
    "            'bootstrap': [True],\n",
    "            'max_samples': np.linspace(.5, 1, 6),\n",
    "        }\n",
    "    ],\n",
    "    # RandomForestClassifier\n",
    "    [\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'n_estimators': [25, 50, 100, 500, 1000],\n",
    "            'bootstrap': [False],\n",
    "        },\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'n_estimators': [25, 50, 100, 500, 1000],\n",
    "            'bootstrap': [True],\n",
    "            'max_samples': np.linspace(.5, 1, 6),\n",
    "        }\n",
    "    ],\n",
    "    # DecisionTreeClassifier\n",
    "    [\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'splitter': ['random', 'best'],\n",
    "        }\n",
    "    ],\n",
    "    # ExtraTreeClassifier\n",
    "    [\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'splitter': ['random', 'best'],\n",
    "        }\n",
    "    ],\n",
    "    # LogisticRegression\n",
    "    [\n",
    "        {\n",
    "            **logistic_params,\n",
    "            'logisticregression__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "            'logisticregression__penalty': ['l1'],\n",
    "        },\n",
    "        {\n",
    "            **logistic_params,\n",
    "            'logisticregression__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "            'logisticregression__penalty': ['l2'],\n",
    "        },\n",
    "        {\n",
    "            **logistic_params,\n",
    "            'logisticregression__solver': ['liblinear'],\n",
    "            'logisticregression__penalty': ['l2'],\n",
    "            'logisticregression__dual': [True, False],\n",
    "        },\n",
    "        {\n",
    "            **logistic_params,\n",
    "            'logisticregression__solver': ['saga'],\n",
    "            'logisticregression__penalty': ['elasticnet'],\n",
    "            'logisticregression__l1_ratio': np.linspace(.1, .9, 9),\n",
    "        }\n",
    "    ],\n",
    "    # PassiveAggressiveClassifier\n",
    "    [\n",
    "        {\n",
    "            'calibratedclassifiercv__base_estimator__C': [.001, .01, .1, 1, 10, 100, 1000],\n",
    "            'calibratedclassifiercv__base_estimator__fit_intercept': [True, False],\n",
    "            'calibratedclassifiercv__base_estimator__max_iter': [1000],\n",
    "            'calibratedclassifiercv__base_estimator__loss': ['hinge', 'squared_hinge'],\n",
    "            'calibratedclassifiercv__base_estimator__average': [True, False],\n",
    "        }\n",
    "    ],\n",
    "    # Perceptron\n",
    "    [\n",
    "        {\n",
    "            'calibratedclassifiercv__base_estimator__penalty': [None, 'l1', 'l2', 'elasticnet'],\n",
    "            'calibratedclassifiercv__base_estimator__fit_intercept': [True, False],\n",
    "            'calibratedclassifiercv__base_estimator__max_iter': [1000],\n",
    "        }\n",
    "    ],\n",
    "    # RidgeClassifier\n",
    "    [\n",
    "        {\n",
    "            'calibratedclassifiercv__base_estimator__alpha': [.001, .01, .1, 1, 10, 100, 1000],\n",
    "            'calibratedclassifiercv__base_estimator__fit_intercept': [True, False],\n",
    "            'calibratedclassifiercv__base_estimator__max_iter': [1000],\n",
    "            'calibratedclassifiercv__base_estimator__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag','saga'],\n",
    "        }\n",
    "    ],\n",
    "    # SGDClassifier\n",
    "    [\n",
    "        {\n",
    "            **sgd_params,\n",
    "            'sgdclassifier__learning_rate': ['optimal'],\n",
    "        },\n",
    "        {\n",
    "            **sgd_params,\n",
    "            'sgdclassifier__learning_rate': ['invscaling', 'adaptive'],\n",
    "            'sgdclassifier__eta0': [.1],\n",
    "        }\n",
    "    ],\n",
    "    # LinearDiscriminantAnalysis\n",
    "    [\n",
    "        {\n",
    "            'lineardiscriminantanalysis__solver': ['svd'],\n",
    "        },\n",
    "        {\n",
    "            'lineardiscriminantanalysis__solver': ['lsqr', 'eigen'],\n",
    "            'lineardiscriminantanalysis__shrinkage': [None, 'auto'] + list(np.linspace(0, 1, 11)),\n",
    "        }\n",
    "    ],\n",
    "    # QuadraticDiscriminantAnalysis\n",
    "    [\n",
    "        {\n",
    "            'quadraticdiscriminantanalysis__reg_param': np.linspace(0, 1, 11),\n",
    "        }\n",
    "    ],\n",
    "    # MLPClassifier\n",
    "    [\n",
    "        {\n",
    "            **mlp_params,\n",
    "            'mlpclassifier__solver': ['lbfgs'],\n",
    "        },\n",
    "        {\n",
    "            **mlp_params,\n",
    "            'mlpclassifier__solver': ['adam'],\n",
    "            'mlpclassifier__learning_rate_init': [.01, .001],\n",
    "        },\n",
    "        {\n",
    "            **mlp_params,\n",
    "            'mlpclassifier__solver': ['sgd'],\n",
    "            'mlpclassifier__learning_rate': ['invscaling', 'adaptive'],\n",
    "            'mlpclassifier__learning_rate_init': [.01, .001],\n",
    "        }\n",
    "    ],\n",
    "    # GaussianProcessClassifier\n",
    "    [\n",
    "        {\n",
    "            'gaussianprocessclassifier__kernel': [x * RBF(x) for x in [.001, .01, .1, 1, 10, 100, 1000]],\n",
    "            'gaussianprocessclassifier__max_iter_predict': [1000],\n",
    "#             'gaussianprocessclassifier__multi_class': ['one_vs_rest', 'one_vs_one'],\n",
    "            'gaussianprocessclassifier__multi_class': ['one_vs_rest'], # Available for roc_auc_ovr metric\n",
    "        }\n",
    "    ],\n",
    "    # BernoulliNB\n",
    "    [\n",
    "        {\n",
    "            **naivebayes_params,\n",
    "        }\n",
    "    ],\n",
    "    # CategoricalNB\n",
    "    [\n",
    "        {\n",
    "            **naivebayes_params,\n",
    "        }\n",
    "    ],\n",
    "    # ComplementNB\n",
    "    [\n",
    "        {\n",
    "            **naivebayes_params,\n",
    "            'norm': [True, False],\n",
    "        }\n",
    "    ],\n",
    "    # GaussianNB\n",
    "    [\n",
    "        {\n",
    "            'var_smoothing': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9],\n",
    "        }\n",
    "    ],\n",
    "    # MultinomialNB\n",
    "    [\n",
    "        {\n",
    "            **naivebayes_params,\n",
    "        }\n",
    "    ],\n",
    "    # DummyClassifier\n",
    "    [\n",
    "        {\n",
    "            'strategy': ['stratified', 'prior', 'uniform'],\n",
    "        }\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_dict = {\n",
    "    'model':             [],\n",
    "    'f1_macro':          [],\n",
    "    'roc_auc_ovr':       [],\n",
    "    'balanced_accuracy': [],\n",
    "    'best_param':        [],\n",
    "    'best_estimator':    [],\n",
    "}\n",
    "\n",
    "for index, (name, estimator) in enumerate(get_estimators()):\n",
    "    print(name)\n",
    "    eval_dict['model'].append(name)\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_distributions=search_params[index],\n",
    "        scoring=['f1_macro', 'roc_auc_ovr', 'balanced_accuracy'],\n",
    "        refit='f1_macro',\n",
    "        cv=StratifiedKFold(n_splits=10),\n",
    "        n_jobs=-1,\n",
    "        verbose=10,\n",
    "        n_iter=100,\n",
    "        random_state=0\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    eval_dict['best_param'].append(\n",
    "        search.best_params_\n",
    "    )\n",
    "    eval_dict['best_estimator'].append(\n",
    "        search.best_estimator_\n",
    "    )\n",
    "    \n",
    "    cv_dict = cross_validation(search.best_estimator_, X_train, y_train)\n",
    "    eval_dict['f1_macro'].append(cv_dict['test_f1_macro'])\n",
    "    eval_dict['roc_auc_ovr'].append(cv_dict['test_roc_auc_ovr'])\n",
    "    eval_dict['balanced_accuracy'].append(cv_dict['test_balanced_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(eval_dict)\n",
    "for cv_score in eval_dict.keys():\n",
    "    if cv_score in ['model', 'best_param', 'best_estimator']:\n",
    "        continue\n",
    "    \n",
    "    eval_df[f'mean_{cv_score}'] = eval_df[cv_score].apply(np.mean)\n",
    "    eval_df[f'std_{cv_score}']  = eval_df[cv_score].apply(np.std)\n",
    "\n",
    "eval_dfs = []\n",
    "for index in eval_df.index:\n",
    "    eval_dfs.append(\n",
    "        pd.DataFrame({\n",
    "            'model': eval_df.at[index, 'model'],\n",
    "            'f1_macro': eval_df.at[index, 'f1_macro'],\n",
    "            'balanced_accuracy': eval_df.at[index, 'balanced_accuracy'],\n",
    "        })\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.box(\n",
    "    pd.concat(eval_dfs, axis=0),\n",
    "    color='model',\n",
    "    max_col=2,\n",
    "    title='Classifier - Tuned',\n",
    "    out_path=OUT_PATH_GRAPH,\n",
    "    layout_kwargs={'showlegend': False},\n",
    "    box_kwargs={\n",
    "        'boxmean': 'sd',\n",
    "        'boxpoints': False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_groups = []\n",
    "annotations = ()\n",
    "\n",
    "for index in tqdm(eval_df.index):\n",
    "    y_pred = eval_df.at[index, 'best_estimator'].predict(X_test)\n",
    "    try:\n",
    "        y_prob = eval_df.at[index, 'best_estimator'].predict_proba(X_test)\n",
    "    except AttributeError:\n",
    "        y_prob = pd.get_dummies(y_pred)\n",
    "    \n",
    "    eval_dict = mlpipe.eval_classif(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        y_prob=y_prob,\n",
    "        multi_class='ovr',\n",
    "        return_evaluation=True,\n",
    "        show_evaluation=False\n",
    "    )\n",
    "    \n",
    "    # Reverse sorting to ensure plotly display is same as dataframe layout\n",
    "    tmp_df = eval_dict['matrix'].sort_index(ascending=False)\n",
    "\n",
    "    # Heatmap data\n",
    "    fig = fig = ff.create_annotated_heatmap(\n",
    "        z=tmp_df.values,\n",
    "        x=[f'Pred {x}' for x in tmp_df.columns],\n",
    "        y=[f'True {x}' for x in tmp_df.index],\n",
    "        colorscale='Portland',\n",
    "        zmin=0,\n",
    "        zmax=y_test.value_counts().values[-1]\n",
    "    )\n",
    "    data_groups.append(fig['data'])\n",
    "    \n",
    "    # Heatmap annotation\n",
    "    annotation = fig['layout']['annotations']\n",
    "    for x in annotation:\n",
    "        suffix = '' if index == 0 else index+1\n",
    "        x['xref'] = f'x{suffix}'\n",
    "        x['yref'] = f'y{suffix}'\n",
    "    annotations += annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.datagroups_subplots(data_groups,\n",
    "                       xaxis_titles=eval_df['model'],\n",
    "                       max_col=4,\n",
    "                       title='Confusion Matrix',\n",
    "                       out_path=OUT_PATH_GRAPH,\n",
    "                       layout_kwargs={\n",
    "                           'height': 2000,\n",
    "                           'annotations': annotations,\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
