{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referance: https://www.youtube.com/watch?v=HdlDYng8g9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib._util.visualplot as vp\n",
    "import lib._util.mlpipe as mlpipe\n",
    "\n",
    "# Feature scaling\n",
    "from lib._class.DFStandardScaler import DFStandardScaler\n",
    "from lib._class.DFRobustScaler import DFRobustScaler\n",
    "from lib._class.DFMinMaxScaler import DFMinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB, ComplementNB, GaussianNB, MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, StackingClassifier\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH_GRAPH = 'resources/output/graph/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data_dict = datasets.load_iris()\n",
    "    \n",
    "    X = pd.DataFrame(\n",
    "        data_dict['data'],\n",
    "        columns=data_dict['feature_names']\n",
    "    )\n",
    "    y = pd.Series(\n",
    "        data_dict['target'],\n",
    "        name='target'\n",
    "    )\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data()\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "vp.value_count(y.to_frame(), 'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Hyperparameter (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(\n",
    "    estimator=SVC(random_state=0),\n",
    "    param_grid={\n",
    "        'C': [1, 10, 20, 30, 40, 50],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "    },\n",
    "    scoring='f1_weighted',\n",
    "    cv=StratifiedKFold(n_splits=10),\n",
    "    n_jobs=-1,\n",
    "    verbose=10,\n",
    ")\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(search.cv_results_)\n",
    "result_df[['params', 'mean_test_score', 'rank_test_score']].sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(**search.best_params_, random_state=0, probability=True)\n",
    "svc.fit(X, y)\n",
    "\n",
    "mlpipe.eval_classif(\n",
    "    y,\n",
    "    svc.predict(X),\n",
    "    y_prob=svc.predict_proba(X),\n",
    "    multi_class='ovr'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Hyperparameter (RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(\n",
    "    estimator=SVC(random_state=0),\n",
    "    param_distributions={\n",
    "        'C': [1, 10, 20, 30, 40, 50],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "    },\n",
    "    scoring='f1_weighted',\n",
    "    cv=StratifiedKFold(n_splits=10),\n",
    "    n_jobs=-1,\n",
    "    verbose=10,\n",
    "    n_iter=10,\n",
    "    random_state=0\n",
    ")\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(search.cv_results_)\n",
    "result_df[['params', 'mean_test_score', 'rank_test_score']].sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(**search.best_params_, random_state=0, probability=True)\n",
    "svc.fit(X, y)\n",
    "\n",
    "mlpipe.eval_classif(\n",
    "    y,\n",
    "    svc.predict(X),\n",
    "    y_prob=svc.predict_proba(X),\n",
    "    multi_class='ovr'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimators():\n",
    "    kwargs1 = {'random_state': 0, 'n_jobs': -1}\n",
    "    kwargs2 = {'n_jobs': -1}\n",
    "    kwargs3 = {'random_state': 0}\n",
    "    \n",
    "    estimators = [\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            KNeighborsClassifier(**kwargs2)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            OneVsRestClassifier(LinearSVC(**kwargs3), **kwargs2)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            OneVsRestClassifier(NuSVC(**kwargs3), **kwargs2)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            OneVsRestClassifier(SVC(**kwargs3), **kwargs2)\n",
    "        ),\n",
    "        XGBClassifier(**kwargs1),\n",
    "        GradientBoostingClassifier(**kwargs3),\n",
    "        ExtraTreesClassifier(**kwargs1),\n",
    "        RandomForestClassifier(**kwargs1),\n",
    "        DecisionTreeClassifier(**kwargs3),\n",
    "        ExtraTreeClassifier(**kwargs3),\n",
    "        make_pipeline(\n",
    "            DFRobustScaler(),\n",
    "            DFMinMaxScaler(),\n",
    "            LogisticRegression(**kwargs1)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFRobustScaler(),\n",
    "            DFMinMaxScaler(),\n",
    "            PassiveAggressiveClassifier(**kwargs1)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFRobustScaler(),\n",
    "            DFMinMaxScaler(),\n",
    "            Perceptron(**kwargs1)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            RidgeClassifier(**kwargs3)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFRobustScaler(),\n",
    "            DFMinMaxScaler(),\n",
    "            SGDClassifier(**kwargs1)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            LinearDiscriminantAnalysis()\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            QuadraticDiscriminantAnalysis()\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFRobustScaler(),\n",
    "            DFMinMaxScaler(),\n",
    "            MLPClassifier(**kwargs3)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            DFStandardScaler(),\n",
    "            GaussianProcessClassifier(**kwargs1)\n",
    "        ),\n",
    "        BernoulliNB(),\n",
    "        CategoricalNB(),\n",
    "        ComplementNB(),\n",
    "        GaussianNB(),\n",
    "        MultinomialNB(),\n",
    "        DummyClassifier(**kwargs3),\n",
    "    ]\n",
    "    \n",
    "    def model_name(model):\n",
    "        name = model.__class__.__name__\n",
    "        if hasattr(model, 'estimator'):\n",
    "            base_name = model.estimator.__class__.__name__\n",
    "            \n",
    "            if name == 'OneVsRestClassifier':\n",
    "                return f'{base_name}_OVR'\n",
    "            else:\n",
    "                return f'{base_name}_{name}'\n",
    "        return name\n",
    "    \n",
    "    return [(model_name(x.steps[-1][1]) if type(x) == Pipeline else model_name(x), x) for x in estimators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(estimator, X, y):\n",
    "    return cross_val_score(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        scoring='f1_macro',\n",
    "        cv=StratifiedKFold(10),\n",
    "        verbose=10,\n",
    "        n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict = {\n",
    "    'model':    [],\n",
    "    'cv_score': [],\n",
    "}\n",
    "\n",
    "for name, estimator in tqdm(get_estimators()):\n",
    "    eval_dict['model'].append(name)\n",
    "    eval_dict['cv_score'].append(\n",
    "        cross_validation(estimator, X, y)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(eval_dict)\n",
    "eval_df['cv_mean'] = eval_df['cv_score'].apply(np.mean)\n",
    "eval_df['cv_std']  = eval_df['cv_score'].apply(np.std)\n",
    "\n",
    "eval_dfs = []\n",
    "for index in eval_df.index:\n",
    "    eval_dfs.append(\n",
    "        pd.DataFrame({\n",
    "            'model': eval_df.at[index, 'model'],\n",
    "            'cv_score': eval_df.at[index, 'cv_score'],\n",
    "        })\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.box(\n",
    "    pd.concat(eval_dfs, axis=0),\n",
    "    color='model',\n",
    "    max_col=1,\n",
    "    title='Classifier - Baseline',\n",
    "    out_path=OUT_PATH_GRAPH,\n",
    "    layout_kwargs={'showlegend': False},\n",
    "    box_kwargs={\n",
    "        'boxmean': 'sd',\n",
    "        'boxpoints': False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kneighbors_params = {\n",
    "    'kneighborsclassifier__n_neighbors': [3, 5, 10, 25, 50, 100],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "    'kneighborsclassifier__metric': ['euclidean', 'manhattan'],\n",
    "}\n",
    "linearsvc_params = {\n",
    "    'onevsrestclassifier__estimator__C': [.001, .01, .1, 1, 10, 100, 1000],\n",
    "    'onevsrestclassifier__estimator__fit_intercept': [True, False],\n",
    "    'onevsrestclassifier__estimator__max_iter': [1000],\n",
    "}\n",
    "nusvc_params = {\n",
    "    'onevsrestclassifier__estimator__nu': np.linspace(.1, 1, 10),\n",
    "    'onevsrestclassifier__estimator__probability': [True],\n",
    "    'onevsrestclassifier__estimator__max_iter': [1000],\n",
    "    'onevsrestclassifier__estimator__decision_function_shape': ['ovr'],\n",
    "    'onevsrestclassifier__estimator__break_ties': [True, False],\n",
    "}\n",
    "svc_params = {\n",
    "    'onevsrestclassifier__estimator__probability': [True],\n",
    "    'onevsrestclassifier__estimator__max_iter': [1000],\n",
    "    'onevsrestclassifier__estimator__decision_function_shape': ['ovr'],\n",
    "    'onevsrestclassifier__estimator__break_ties': [True, False],\n",
    "}\n",
    "tree_params = {\n",
    "    'max_depth': [None, 3, 5, 7, 10, 15],\n",
    "    'min_samples_split': np.linspace(.1, 1, 10),\n",
    "    'min_samples_leaf': np.linspace(.1, .5, 5),\n",
    "    'max_features': ['sqrt', 'log2'] + list(np.linspace(.5, 1, 6)),\n",
    "}\n",
    "logistic_params = {\n",
    "    'logisticregression__C': [.001, .01, .1, 1, 10, 100, 1000],\n",
    "    'logisticregression__fit_intercept': [True, False],\n",
    "    'logisticregression__max_iter': [1000],\n",
    "    'logisticregression__multi_class': ['auto'],\n",
    "}\n",
    "sgd_params = {\n",
    "    'sgdclassifier__loss': ['hinge', 'modified_huber', 'squared_hinge',\n",
    "                            'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'sgdclassifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'sgdclassifier__l1_ratio': np.linspace(.1, .9, 9),\n",
    "    'sgdclassifier__fit_intercept': [True, False],\n",
    "    'sgdclassifier__max_iter': [1000],\n",
    "    'sgdclassifier__average': [True, False],\n",
    "}\n",
    "mlp_params = {\n",
    "    'mlpclassifier__hidden_layer_sizes': [(100,), (32, 64, 128) , (128, 64, 32)],\n",
    "    'mlpclassifier__activation': ['relu'],\n",
    "    'mlpclassifier__max_iter': [1000],\n",
    "}\n",
    "naivebayes_params = {\n",
    "    'alpha': np.linspace(0, 1, 11),\n",
    "    'fit_prior': [True, False],\n",
    "}\n",
    "\n",
    "\n",
    "search_params = [\n",
    "    # KNeighborsClassifier\n",
    "    [\n",
    "        {\n",
    "            **kneighbors_params,\n",
    "            'kneighborsclassifier__algorithm': ['ball_tree', 'kd_tree'],\n",
    "            'kneighborsclassifier__leaf_size': [3, 30, 300, 3000],\n",
    "        },\n",
    "        {\n",
    "            **kneighbors_params,\n",
    "            'kneighborsclassifier__algorithm': ['brute'],\n",
    "        }\n",
    "    ],\n",
    "    # LinearSVC\n",
    "    [\n",
    "        {\n",
    "            **linearsvc_params,\n",
    "            'onevsrestclassifier__estimator__multi_class': ['ovr'],\n",
    "            'onevsrestclassifier__estimator__penalty': ['l1', 'l2'],\n",
    "            'onevsrestclassifier__estimator__loss': ['hinge', 'squared_hinge'],\n",
    "            'onevsrestclassifier__estimator__dual': [True, False],\n",
    "        },\n",
    "        {\n",
    "            **linearsvc_params,\n",
    "            'onevsrestclassifier__estimator__multi_class': ['crammer_singer'],\n",
    "        }\n",
    "    ],\n",
    "    # NuSVC\n",
    "    [\n",
    "        {\n",
    "            **nusvc_params,\n",
    "            'onevsrestclassifier__estimator__kernel': ['linear', 'precomputed'],\n",
    "            \n",
    "        },\n",
    "        {\n",
    "            **nusvc_params,\n",
    "            'onevsrestclassifier__estimator__kernel': ['rbf', 'sigmoid'],\n",
    "            'onevsrestclassifier__estimator__gamma': [.001, .01, .1, 1, 10, 100, 1000, 'scale', 'auto'],\n",
    "        },\n",
    "        {\n",
    "            **nusvc_params,\n",
    "            'onevsrestclassifier__estimator__kernel': ['poly'],\n",
    "            'onevsrestclassifier__estimator__gamma': [.001, .01, .1, 1, 10, 100, 1000, 'scale', 'auto'],\n",
    "            'onevsrestclassifier__estimator__degree': [.003, .03, .3, 3, 30, 300, 3000],\n",
    "        }\n",
    "    ],\n",
    "    # SVC\n",
    "    [\n",
    "        {\n",
    "            **svc_params,\n",
    "            'onevsrestclassifier__estimator__kernel': ['linear', 'precomputed'],\n",
    "        },\n",
    "        {\n",
    "            **svc_params,\n",
    "            'onevsrestclassifier__estimator__kernel': ['rbf', 'sigmoid'],\n",
    "            'onevsrestclassifier__estimator__gamma': [.001, .01, .1, 1, 10, 100, 1000, 'scale', 'auto'],\n",
    "        },\n",
    "        {\n",
    "            **svc_params,\n",
    "            'onevsrestclassifier__estimator__kernel': ['poly'],\n",
    "            'onevsrestclassifier__estimator__gamma': [.001, .01, .1, 1, 10, 100, 1000, 'scale', 'auto'],\n",
    "            'onevsrestclassifier__estimator__degree': [.003, .03, .3, 3, 30, 300, 3000],\n",
    "        }\n",
    "    ],\n",
    "    # XGBClassifier\n",
    "    [\n",
    "        {\n",
    "            'n_estimators': [25, 50, 100, 500, 1000],\n",
    "            'max_depth': [None, 3, 5, 7, 10, 15],\n",
    "            'learning_rate': [.1, .01],\n",
    "            'objective':['reg:logistic'],\n",
    "            'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "            'subsample': [.8],\n",
    "            'colsample_bytree': np.linspace(.5, 1, 6),\n",
    "            'reg_alpha': np.linspace(0, 1, 11),\n",
    "            'reg_lambda': np.linspace(0, 1, 11),\n",
    "        }\n",
    "    ],\n",
    "    # GradientBoostingClassifier\n",
    "    [\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "            'n_estimators': [25, 50, 100, 500, 1000],\n",
    "            'loss': ['deviance', 'exponential'],\n",
    "            'learning_rate': [.1, .01],\n",
    "            'subsample': np.linspace(.5, 1, 6),\n",
    "        }\n",
    "    ],\n",
    "    # ExtraTreesClassifier\n",
    "    [\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'n_estimators': [25, 50, 100, 500, 1000],\n",
    "            'oob_score': [True, False],\n",
    "            'bootstrap': [False],\n",
    "        },\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'n_estimators': [25, 50, 100, 500, 1000],\n",
    "            'oob_score': [True, False],\n",
    "            'bootstrap': [True],\n",
    "            'max_samples': np.linspace(.5, 1, 6),\n",
    "        }\n",
    "    ],\n",
    "    # RandomForestClassifier\n",
    "    [\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'n_estimators': [25, 50, 100, 500, 1000],\n",
    "            'bootstrap': [False],\n",
    "        },\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'n_estimators': [25, 50, 100, 500, 1000],\n",
    "            'bootstrap': [True],\n",
    "            'max_samples': np.linspace(.5, 1, 6),\n",
    "        }\n",
    "    ],\n",
    "    # DecisionTreeClassifier\n",
    "    [\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'splitter': ['best'],\n",
    "        }\n",
    "    ],\n",
    "    # ExtraTreeClassifier\n",
    "    [\n",
    "        {\n",
    "            **tree_params,\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'splitter': ['best'],\n",
    "        }\n",
    "    ],\n",
    "    # LogisticRegression\n",
    "    [\n",
    "        {\n",
    "            **logistic_params,\n",
    "            'logisticregression__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "            'logisticregression__penalty': ['l1'],\n",
    "        },\n",
    "        {\n",
    "            **logistic_params,\n",
    "            'logisticregression__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "            'logisticregression__penalty': ['l2'],\n",
    "        },\n",
    "        {\n",
    "            **logistic_params,\n",
    "            'logisticregression__solver': ['liblinear '],\n",
    "            'logisticregression__penalty': ['l2'],\n",
    "            'logisticregression__dual': [True, False],\n",
    "        },\n",
    "        {\n",
    "            **logistic_params,\n",
    "            'logisticregression__solver': ['saga'],\n",
    "            'logisticregression__penalty': ['elasticnet'],\n",
    "            'logisticregression__l1_ratio': np.linspace(.1, .9, 9),\n",
    "        }\n",
    "    ],\n",
    "    # PassiveAggressiveClassifier\n",
    "    [\n",
    "        {\n",
    "            'passiveaggressiveclassifier__C': [.001, .01, .1, 1, 10, 100, 1000],\n",
    "            'passiveaggressiveclassifier__fit_intercept': [True, False],\n",
    "            'passiveaggressiveclassifier__max_iter': [1000],\n",
    "            'passiveaggressiveclassifier__loss': ['hinge', 'squared_hinge'],\n",
    "            'passiveaggressiveclassifier__average': [True, False],\n",
    "        }\n",
    "    ],\n",
    "    # Perceptron\n",
    "    [\n",
    "        {\n",
    "            'perceptron__penalty': [None, 'l1', 'l2', 'elasticnet'],\n",
    "            'perceptron__fit_intercept': [True, False],\n",
    "            'perceptron__max_iter': [1000],\n",
    "        }\n",
    "    ],\n",
    "    # RidgeClassifier\n",
    "    [\n",
    "        {\n",
    "            'ridgeclassifier__alpha': [.001, .01, .1, 1, 10, 100, 1000],\n",
    "            'ridgeclassifier__fit_intercept': [True, False],\n",
    "            'ridgeclassifier__max_iter': [1000],\n",
    "            'ridgeclassifier__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag','saga'],\n",
    "        }\n",
    "    ],\n",
    "    # SGDClassifier\n",
    "    [\n",
    "        {\n",
    "            **sgd_params,\n",
    "            'sgdclassifier__learning_rate': ['optimal'],\n",
    "        },\n",
    "        {\n",
    "            **sgd_params,\n",
    "            'sgdclassifier__learning_rate': ['invscaling', 'adaptive'],\n",
    "            'sgdclassifier__eta0': [.1],\n",
    "        }\n",
    "    ],\n",
    "    # LinearDiscriminantAnalysis\n",
    "    [\n",
    "        {\n",
    "            'lineardiscriminantanalysis__solver': ['svd'],\n",
    "        },\n",
    "        {\n",
    "            'lineardiscriminantanalysis__solver': ['lsqr', 'eigen'],\n",
    "            'lineardiscriminantanalysis__shrinkage': ['auto'] + list(np.linspace(0, 1, 11)),\n",
    "        }\n",
    "    ],\n",
    "    # QuadraticDiscriminantAnalysis\n",
    "    [\n",
    "        {\n",
    "            'quadraticdiscriminantanalysis__reg_param': np.linspace(0, 1, 11),\n",
    "        }\n",
    "    ],\n",
    "    # MLPClassifier\n",
    "    [\n",
    "        {\n",
    "            **mlp_params,\n",
    "            'mlpclassifier__solver': ['lbfgs'],\n",
    "        },\n",
    "        {\n",
    "            **mlp_params,\n",
    "            'mlpclassifier__solver': ['adam'],\n",
    "            'mlpclassifier__learning_rate_init': [.01, .001],\n",
    "        },\n",
    "        {\n",
    "            **mlp_params,\n",
    "            'mlpclassifier__solver': ['sgd'],\n",
    "            'mlpclassifier__learning_rate': ['invscaling', 'adaptive'],\n",
    "            'mlpclassifier__learning_rate_init': [.01, .001],\n",
    "        }\n",
    "    ],\n",
    "    # GaussianProcessClassifier\n",
    "    [\n",
    "        {\n",
    "            'gaussianprocessclassifier__kernel': [x * RBF(x) for x in [.001, .01, .1, 1, 10, 100, 1000]],\n",
    "            'gaussianprocessclassifier__max_iter_predict': [1000],\n",
    "            'gaussianprocessclassifier__multi_class': ['one_vs_rest', 'one_vs_one'],\n",
    "        }\n",
    "    ],\n",
    "    # BernoulliNB\n",
    "    [\n",
    "        {\n",
    "            **naivebayes_params,\n",
    "        }\n",
    "    ],\n",
    "    # CategoricalNB\n",
    "    [\n",
    "        {\n",
    "            **naivebayes_params,\n",
    "        }\n",
    "    ],\n",
    "    # ComplementNB\n",
    "    [\n",
    "        {\n",
    "            **naivebayes_params,\n",
    "            'norm': [True, False],\n",
    "        }\n",
    "    ],\n",
    "    # GaussianNB\n",
    "    [\n",
    "        {\n",
    "            'var_smoothing': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9],\n",
    "        }\n",
    "    ],\n",
    "    # MultinomialNB\n",
    "    [\n",
    "        {\n",
    "            **naivebayes_params,\n",
    "        }\n",
    "    ],\n",
    "    # DummyClassifier\n",
    "    [\n",
    "        {\n",
    "            'strategy': ['stratified', 'prior', 'uniform'],\n",
    "        }\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_dict = {\n",
    "    'model':          [],\n",
    "    'cv_score':       [],\n",
    "    'best_param':     [],\n",
    "    'best_estimator': [],\n",
    "}\n",
    "\n",
    "for index, (name, estimator) in enumerate(get_estimators()):\n",
    "    print(name)\n",
    "    eval_dict['model'].append(name)\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_distributions=search_params[index],\n",
    "        scoring='f1_weighted',\n",
    "        cv=StratifiedKFold(n_splits=10),\n",
    "        n_jobs=-1,\n",
    "        verbose=10,\n",
    "        refit=True,\n",
    "        n_iter=100,\n",
    "        random_state=0\n",
    "    )\n",
    "    search.fit(X, y)\n",
    "    eval_dict['best_param'].append(\n",
    "        search.best_params_\n",
    "    )\n",
    "    eval_dict['best_estimator'].append(\n",
    "        search.best_estimator_\n",
    "    )\n",
    "    eval_dict['cv_score'].append(\n",
    "        cross_validation(search.best_estimator_, X, y)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(eval_dict)\n",
    "eval_df['cv_mean'] = eval_df['cv_score'].apply(np.mean)\n",
    "eval_df['cv_std']  = eval_df['cv_score'].apply(np.std)\n",
    "\n",
    "eval_dfs = []\n",
    "for index in eval_df.index:\n",
    "    eval_dfs.append(\n",
    "        pd.DataFrame({\n",
    "            'model': eval_df.at[index, 'model'],\n",
    "            'cv_score': eval_df.at[index, 'cv_score'],\n",
    "        })\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.box(\n",
    "    pd.concat(eval_dfs, axis=0),\n",
    "    color='model',\n",
    "    max_col=1,\n",
    "    title='Classifier - Tuned',\n",
    "    out_path=OUT_PATH_GRAPH,\n",
    "    layout_kwargs={'showlegend': False},\n",
    "    box_kwargs={\n",
    "        'boxmean': 'sd',\n",
    "        'boxpoints': False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
