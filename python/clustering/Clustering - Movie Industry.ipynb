{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib._util.visualplot as vp\n",
    "\n",
    "# Pre-processing\n",
    "from lib._class.DFDuplicateRemoval import DFDuplicateRemoval\n",
    "\n",
    "# Feature selection\n",
    "from lib._class.DFVarianceThreshold import DFVarianceThreshold\n",
    "from lib._class.DFVIFThreshold import DFVIFThreshold\n",
    "\n",
    "# Feature encoding\n",
    "from lib._class.DFLabelEncoder import DFLabelEncoder\n",
    "from lib._class.DFOneHotEncoder import DFOneHotEncoder\n",
    "\n",
    "# Feature scaling\n",
    "from lib._class.DFStandardScaler import DFStandardScaler\n",
    "from lib._class.DFMinMaxScaler import DFMinMaxScaler\n",
    "\n",
    "# Feature extraction\n",
    "from lib._class.DFIvis import DFIvis\n",
    "\n",
    "# Clustering\n",
    "from lib._class.DFKMeans import DFKMeans\n",
    "from lib._class.DFKMedoids import DFKMedoids\n",
    "from lib._class.DFGaussianMixture import DFGaussianMixture\n",
    "from lib._class.DFAgglomerative import DFAgglomerative\n",
    "from lib._class.DFDBSCAN import DFDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH_DATA = 'resources/data/'\n",
    "OUT_PATH_GRAPH   = 'resources/output/graph/movie/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Data Loading\n",
    "- Reference: https://www.kaggle.com/danielgrijalvas/movies#movies.csv\n",
    "- budget: the budget of a movie. Some movies don't have this, so it appears as 0\n",
    "- company: the production company\n",
    "- country: country of origin\n",
    "- director: the director\n",
    "- genre: main genre of the movie.\n",
    "- gross: revenue of the movie\n",
    "- name: name of the movie\n",
    "- rating: rating of the movie (R, PG, etc.)\n",
    "- released: release date (YYYY-MM-DD)\n",
    "- runtime: duration of the movie\n",
    "- score: IMDb user rating\n",
    "- votes: number of user votes\n",
    "- star: main actor/actress\n",
    "- writer: writer of the movie\n",
    "- year: year of release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(f'{SOURCE_PATH_DATA}movies.csv', sep=',', encoding='latin-1',\n",
    "                      parse_dates=['released'])\n",
    "\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize letter case\n",
    "for column in data_df.select_dtypes(include='object').columns:\n",
    "    data_df[column] = data_df[column].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.histogram(data_df,\n",
    "             bin_algo='count',\n",
    "             max_col=3,\n",
    "             title='Phase 1 - Histogram',\n",
    "             out_path=OUT_PATH_GRAPH,\n",
    "             layout_kwargs={'height': 1500},\n",
    "             str_length=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 - Data Preparation\n",
    "- Handle high cardinality features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(data_df.select_dtypes(include='object'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select companies occurs at least 100 times\n",
    "count_df = data_df['company'].value_counts().to_frame(name='count')\n",
    "data_df['company'] = np.where(data_df['company'].isin(count_df[count_df['count'] >= 100].index),\n",
    "                              data_df['company'], 'other')\n",
    "del count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'company')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select countries occurs at least 20 times\n",
    "count_df = data_df['country'].value_counts().to_frame(name='count')\n",
    "data_df['country'] = np.where(data_df['country'].isin(count_df[count_df['count'] >= 20].index),\n",
    "                              data_df['country'], 'other')\n",
    "del count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'director')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select directors occurs at least 15 times\n",
    "count_df = data_df['director'].value_counts().to_frame(name='count')\n",
    "data_df['director'] = np.where(data_df['director'].isin(count_df[count_df['count'] >= 15].index),\n",
    "                               data_df['director'], 'other')\n",
    "del count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'director')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select genre occurs at least 10 times\n",
    "count_df = data_df['genre'].value_counts().to_frame(name='count')\n",
    "data_df['genre'] = np.where(data_df['genre'].isin(count_df[count_df['count'] >= 10].index),\n",
    "                            data_df['genre'], 'other')\n",
    "del count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove movie name as most of them are unique, and it's more suitable for text mining\n",
    "data_df.drop(columns=['name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference:\n",
    "# - https://en.wikipedia.org/wiki/Motion_Picture_Association_of_America_film_rating_system\n",
    "# - https://rating-system.fandom.com/wiki/Mexico_movie_rating_system\n",
    "# - https://en.wikipedia.org/wiki/TV_Parental_Guidelines\n",
    "data_df['rating'] = np.where(data_df['rating'].isin(['not rated', 'unrated']), 'nr/ur', data_df['rating'])\n",
    "data_df['rating'] = np.where(data_df['rating'].isin(['pg', 'tv-pg']), 'pg/tv-pg', data_df['rating'])\n",
    "data_df['rating'] = np.where(data_df['rating'].isin(['pg-13', 'tv-14']), 'pg-13/tv-14', data_df['rating'])\n",
    "data_df['rating'] = np.where(data_df['rating'].isin(['nc-17', 'tv-ma']), 'nc-17/tv-ma', data_df['rating'])\n",
    "data_df['rating'] = np.where(data_df['rating'].isin(['r', 'b', 'b15']), 'r/b/b15', data_df['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'star')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select stars occurs at least 25 times\n",
    "count_df = data_df['star'].value_counts().to_frame(name='count')\n",
    "data_df['star'] = np.where(data_df['star'].isin(count_df[count_df['count'] >= 25].index),\n",
    "                           data_df['star'], 'other')\n",
    "del count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'star')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'writer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select writers occurs at least 10 times\n",
    "count_df = data_df['writer'].value_counts().to_frame(name='count')\n",
    "data_df['writer'] = np.where(data_df['writer'].isin(count_df[count_df['count'] >= 10].index),\n",
    "                             data_df['writer'], 'other')\n",
    "del count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'writer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.histogram(data_df,\n",
    "             bin_algo='count',\n",
    "             max_col=3,\n",
    "             title='Phase 2 - Histogram',\n",
    "             out_path=OUT_PATH_GRAPH,\n",
    "             layout_kwargs={'height': 1500},\n",
    "             str_length=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 - Data Preparation\n",
    "- Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature enginnering from date\n",
    "data_df['release_year']  = data_df['released'].dt.year\n",
    "data_df['release_month'] = data_df['released'].dt.month\n",
    "data_df['release_day']   = data_df['released'].dt.day\n",
    "data_df['day_of_year']   = data_df['released'].dt.dayofyear\n",
    "data_df['day_of_week']   = data_df['released'].dt.dayofweek\n",
    "data_df['week_of_year']  = data_df['released'].dt.weekofyear\n",
    "data_df['quarter']       = data_df['released'].dt.quarter\n",
    "\n",
    "# Remove date feature\n",
    "data_df.drop(columns=['released'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.histogram(data_df,\n",
    "             bin_algo='count',\n",
    "             max_col=3,\n",
    "             title='Phase 3 - Histogram',\n",
    "             out_path=OUT_PATH_GRAPH,\n",
    "             layout_kwargs={'height': 2000},\n",
    "             str_length=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4 - Data Preparation\n",
    "- Remove duplication\n",
    "- Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df.copy()\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated data\n",
    "duplicate_removal = DFDuplicateRemoval()\n",
    "X = duplicate_removal.fit_transform(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_removal.duplicate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove low variance feature\n",
    "label_encoder      = DFLabelEncoder(columns=X.select_dtypes(include='object').columns)\n",
    "variance_threshold = DFVarianceThreshold(threshold=.01)\n",
    "\n",
    "steps = [\n",
    "    ('label_encoder', label_encoder),\n",
    "    ('variance_threshold', variance_threshold),\n",
    "]\n",
    "Pipeline(steps).fit(X)\n",
    "\n",
    "# Prevent inverse_transform which cause loss of original data type\n",
    "X.drop(columns=variance_threshold.stat_df[~variance_threshold.stat_df['support']]['feature'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_threshold.stat_df[~variance_threshold.stat_df['support']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES = list(X.select_dtypes(include='object').columns)\n",
    "NUMERICAL_FEATURES   = list(X.select_dtypes(include='number').columns)\n",
    "\n",
    "CATEGORICAL_FEATURES, NUMERICAL_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove high VIF feature\n",
    "onehot_encoder  = DFOneHotEncoder(columns=CATEGORICAL_FEATURES, dtype='byte')\n",
    "standard_scaler = DFStandardScaler(columns=NUMERICAL_FEATURES)\n",
    "minmax_scaler   = DFMinMaxScaler(columns=NUMERICAL_FEATURES)\n",
    "vif_threshold   = DFVIFThreshold(show_progress=True)\n",
    "\n",
    "steps = [\n",
    "    ('onehot_encoder', onehot_encoder),\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "    ('vif_threshold', vif_threshold),\n",
    "]\n",
    "X = Pipeline(steps).fit_transform(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_df = vif_threshold.calc_vif(X)\n",
    "vif_df.reset_index(inplace=True)\n",
    "vif_df.rename(columns={'index': 'feature'}, inplace=True)\n",
    "vif_df = vif_df[vif_df['feature'] != 'const'].copy()\n",
    "\n",
    "fig = px.bar(vif_df, x='feature', y='VIF')\n",
    "vp.generate_plot(fig,\n",
    "                 out_path=OUT_PATH_GRAPH,\n",
    "                 out_filename='Phase 4 - Bar - VIF')\n",
    "del vif_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5 - Data Preparation\n",
    "- Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ivis    = DFIvis(k=15, n_epochs_without_progress=20, model='maaten', verbose=2, epochs=100)\n",
    "ivis_df = ivis.fit_transform(X)\n",
    "\n",
    "ivis_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(ivis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.scatter(ivis_df,\n",
    "           xy_tuples=[('ivis_0', 'ivis_1')],\n",
    "           max_col=1,\n",
    "           title='Phase 5 - Scatter',\n",
    "           out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 6 - Clustering\n",
    "- K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters\n",
    "kmeans = DFKMeans(cluster_name='KMeans', n_clusters=15, random_state=0, n_jobs=-1,\n",
    "                  eval_inertia=True, eval_silhouette=True, eval_chi=True, eval_dbi=True)\n",
    "kmeans.fit(ivis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(kmeans.eval_df,\n",
    "        xy_tuples=[('n_cluster', x) for x in ['inertia', 'silhouette', 'calinski_harabasz', 'davies_bouldin']],\n",
    "        max_col=2,\n",
    "        title='Phase 6 - N Cluster - K-Means',\n",
    "        out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters by scores\n",
    "kmeans.eval_df.loc[kmeans.eval_df['silhouette'].idxmax()]['n_cluster'],\\\n",
    "kmeans.eval_df.loc[kmeans.eval_df['calinski_harabasz'].idxmax()]['n_cluster'],\\\n",
    "kmeans.eval_df.loc[kmeans.eval_df['davies_bouldin'].idxmin()]['n_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "kmeans     = DFKMeans(cluster_name='KMeans', n_clusters=2, random_state=0, n_jobs=-1)\n",
    "cluster_df = kmeans.fit_predict(ivis_df)\n",
    "\n",
    "vp.value_count(cluster_df, 'KMeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = cluster_df.copy()\n",
    "tmp_df.sort_values(by='KMeans', inplace=True)\n",
    "tmp_df['KMeans'] = tmp_df['KMeans'].astype(str)\n",
    "\n",
    "vp.scatter(tmp_df,\n",
    "           xy_tuples=[('ivis_0', 'ivis_1')],\n",
    "           color='KMeans',\n",
    "           max_col=1,\n",
    "           title='Phase 6 - Scatter - K-Means',\n",
    "           out_path=OUT_PATH_GRAPH)\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['KMeans']], data_df], axis=1)\n",
    "tmp_df['KMeans'] = tmp_df['KMeans'].astype(str)\n",
    "\n",
    "vp.box(tmp_df,\n",
    "       color='KMeans',\n",
    "       max_col=2,\n",
    "       title='Phase 6 - Box - K-Means',\n",
    "       out_path=OUT_PATH_GRAPH,\n",
    "       layout_kwargs={\n",
    "           'showlegend': False,\n",
    "           'height': 1500\n",
    "       })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distribution Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['KMeans']], data_df], axis=1)\n",
    "\n",
    "vp.distmat(tmp_df,\n",
    "           target='KMeans',\n",
    "           title='Phase 6 - Distribution Matrix - K-Means',\n",
    "           out_path=OUT_PATH_GRAPH,\n",
    "           heatmap_kwargs={\n",
    "               'colorscale': 'Dense',\n",
    "               'zmin': 0,\n",
    "               'zmax': 1\n",
    "           })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 7 - Clustering\n",
    "- Gaussian mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters\n",
    "gmm = DFGaussianMixture(cluster_name='GMM', n_components=15, random_state=0,\n",
    "                        eval_aic=True, eval_bic=True, eval_silhouette=True, eval_chi=True, eval_dbi=True)\n",
    "gmm.fit(ivis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(gmm.eval_df,\n",
    "        xy_tuples=[('n_cluster', x) for x in ['akaike', 'bayesian', 'silhouette', 'calinski_harabasz', 'davies_bouldin']],\n",
    "        max_col=3,\n",
    "        title='Phase 7 - N Cluster - GMM',\n",
    "        out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters by scores\n",
    "gmm.eval_df.loc[gmm.eval_df['akaike'].idxmin()]['n_cluster'],\\\n",
    "gmm.eval_df.loc[gmm.eval_df['bayesian'].idxmin()]['n_cluster'],\\\n",
    "gmm.eval_df.loc[gmm.eval_df['silhouette'].idxmax()]['n_cluster'],\\\n",
    "gmm.eval_df.loc[gmm.eval_df['calinski_harabasz'].idxmax()]['n_cluster'],\\\n",
    "gmm.eval_df.loc[gmm.eval_df['davies_bouldin'].idxmin()]['n_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "gmm        = DFGaussianMixture(cluster_name='GMM', n_components=2, random_state=0)\n",
    "cluster_df = gmm.fit_predict(ivis_df)\n",
    "\n",
    "vp.value_count(cluster_df, 'GMM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = cluster_df.copy()\n",
    "tmp_df.sort_values(by='GMM', inplace=True)\n",
    "tmp_df['GMM'] = tmp_df['GMM'].astype(str)\n",
    "\n",
    "vp.scatter(tmp_df,\n",
    "           xy_tuples=[('ivis_0', 'ivis_1')],\n",
    "           color='GMM',\n",
    "           max_col=1,\n",
    "           title='Phase 7 - Scatter - GMM',\n",
    "           out_path=OUT_PATH_GRAPH)\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['GMM']], data_df], axis=1)\n",
    "tmp_df['GMM'] = tmp_df['GMM'].astype(str)\n",
    "\n",
    "vp.box(tmp_df,\n",
    "       color='GMM',\n",
    "       max_col=2,\n",
    "       title='Phase 7 - Box - GMM',\n",
    "       out_path=OUT_PATH_GRAPH,\n",
    "       layout_kwargs={\n",
    "           'showlegend': False,\n",
    "           'height': 1500\n",
    "       })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distribution Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['GMM']], data_df], axis=1)\n",
    "\n",
    "vp.distmat(tmp_df,\n",
    "           target='GMM',\n",
    "           title='Phase 7 - Distribution Matrix - GMM',\n",
    "           out_path=OUT_PATH_GRAPH,\n",
    "           heatmap_kwargs={\n",
    "               'colorscale': 'Dense',\n",
    "               'zmin': 0,\n",
    "               'zmax': 1\n",
    "           })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 8 - Clustering\n",
    "- Agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://stackabuse.com/hierarchical-clustering-with-python-and-scikit-learn/\n",
    "# Determine number of clusters\n",
    "agglo = DFAgglomerative(cluster_name='Agglo', n_clusters=15, random_state=0,\n",
    "                        eval_silhouette=True, eval_chi=True, eval_dbi=True)\n",
    "agglo.fit(ivis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(agglo.eval_df,\n",
    "        xy_tuples=[('n_cluster', x) for x in ['silhouette', 'calinski_harabasz', 'davies_bouldin']],\n",
    "        max_col=2,\n",
    "        title='Phase 8 - N Cluster - Agglomerative',\n",
    "        out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.dendrogram(ivis_df,\n",
    "              title='Phase 8 - Dendrogram - Agglomerative',\n",
    "              out_path=OUT_PATH_GRAPH,\n",
    "              layout_kwargs={\n",
    "                  'width': 1350,\n",
    "                  'height': 600\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters by scores\n",
    "agglo.eval_df.loc[agglo.eval_df['silhouette'].idxmax()]['n_cluster'],\\\n",
    "agglo.eval_df.loc[agglo.eval_df['calinski_harabasz'].idxmax()]['n_cluster'],\\\n",
    "agglo.eval_df.loc[agglo.eval_df['davies_bouldin'].idxmin()]['n_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "agglo      = DFAgglomerative(cluster_name='Agglo', n_clusters=2, random_state=0)\n",
    "cluster_df = agglo.fit_predict(ivis_df)\n",
    "\n",
    "vp.value_count(cluster_df, 'Agglo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = cluster_df.copy()\n",
    "tmp_df.sort_values(by='Agglo', inplace=True)\n",
    "tmp_df['Agglo'] = tmp_df['Agglo'].astype(str)\n",
    "\n",
    "vp.scatter(tmp_df,\n",
    "           xy_tuples=[('ivis_0', 'ivis_1')],\n",
    "           color='Agglo',\n",
    "           max_col=1,\n",
    "           title='Phase 8 - Scatter - Agglomerative',\n",
    "           out_path=OUT_PATH_GRAPH)\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['Agglo']], data_df], axis=1)\n",
    "tmp_df['Agglo'] = tmp_df['Agglo'].astype(str)\n",
    "\n",
    "vp.box(tmp_df,\n",
    "       color='Agglo',\n",
    "       max_col=2,\n",
    "       title='Phase 8 - Box - Agglomerative',\n",
    "       out_path=OUT_PATH_GRAPH,\n",
    "       layout_kwargs={\n",
    "           'showlegend': False,\n",
    "           'height': 1500\n",
    "       })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distribution Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['Agglo']], data_df], axis=1)\n",
    "\n",
    "vp.distmat(tmp_df,\n",
    "           target='Agglo',\n",
    "           title='Phase 8 - Distribution Matrix - Agglomerative',\n",
    "           out_path=OUT_PATH_GRAPH,\n",
    "           heatmap_kwargs={\n",
    "               'colorscale': 'Dense',\n",
    "               'zmin': 0,\n",
    "               'zmax': 1\n",
    "           })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 9 - Clustering\n",
    "- DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine hyperparameters with highest score\n",
    "dbscan = DFDBSCAN(cluster_name='DBSCAN', random_state=0, n_jobs=-1,\n",
    "                  eps_samples_tuples=[(round(x,5), 5) for x in np.arange(.1, 2, .1)],\n",
    "                  eval_cluster=True, eval_silhouette=True, eval_chi=True, eval_dbi=True)\n",
    "dbscan.fit(ivis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(dbscan.eval_df,\n",
    "        xy_tuples=[('eps', x) for x in ['n_cluster', 'n_noise',\n",
    "                                        'silhouette', 'silhouette_w/o_noise',\n",
    "                                        'calinski_harabasz', 'calinski_harabasz_w/o_noise',\n",
    "                                        'davies_bouldin', 'davies_bouldin_w/o_noise']],\n",
    "        max_col=4,\n",
    "        title='Phase 9 - EPS Evaluation - DBSCAN',\n",
    "        out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine EPS by scores\n",
    "dbscan.eval_df.loc[dbscan.eval_df['silhouette'].idxmax()]['eps'],\\\n",
    "dbscan.eval_df.loc[dbscan.eval_df['silhouette_w/o_noise'].idxmax()]['eps'],\\\n",
    "dbscan.eval_df.loc[dbscan.eval_df['calinski_harabasz'].idxmax()]['eps'],\\\n",
    "dbscan.eval_df.loc[dbscan.eval_df['calinski_harabasz_w/o_noise'].idxmax()]['eps'],\\\n",
    "dbscan.eval_df.loc[dbscan.eval_df['davies_bouldin'].idxmin()]['eps'], \\\n",
    "dbscan.eval_df.loc[dbscan.eval_df['davies_bouldin_w/o_noise'].idxmin()]['eps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "dbscan     = DFDBSCAN(cluster_name='DBSCAN', random_state=0, n_jobs=-1, eps=1.5, min_samples=5)\n",
    "cluster_df = dbscan.fit_predict(ivis_df)\n",
    "\n",
    "vp.value_count(cluster_df, 'DBSCAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = cluster_df.copy()\n",
    "tmp_df.sort_values(by='DBSCAN', inplace=True)\n",
    "tmp_df['DBSCAN'] = tmp_df['DBSCAN'].astype(str)\n",
    "\n",
    "vp.scatter(tmp_df,\n",
    "           xy_tuples=[('ivis_0', 'ivis_1')],\n",
    "           color='DBSCAN',\n",
    "           max_col=1,\n",
    "           title='Phase 9 - Scatter - DBSCAN',\n",
    "           out_path=OUT_PATH_GRAPH)\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['DBSCAN']], data_df], axis=1)\n",
    "tmp_df['DBSCAN'] = tmp_df['DBSCAN'].astype(str)\n",
    "\n",
    "vp.box(tmp_df,\n",
    "       color='DBSCAN',\n",
    "       max_col=2,\n",
    "       title='Phase 9 - Box - DBSCAN',\n",
    "       out_path=OUT_PATH_GRAPH,\n",
    "       layout_kwargs={\n",
    "           'showlegend': False,\n",
    "           'height': 1500\n",
    "       })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distribution Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['DBSCAN']], data_df], axis=1)\n",
    "\n",
    "vp.distmat(tmp_df,\n",
    "           target='DBSCAN',\n",
    "           title='Phase 9 - Distribution Matrix - DBSCAN',\n",
    "           out_path=OUT_PATH_GRAPH,\n",
    "           heatmap_kwargs={\n",
    "               'colorscale': 'Dense',\n",
    "               'zmin': 0,\n",
    "               'zmax': 1\n",
    "           })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 10 - Clustering\n",
    "- K-Medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters\n",
    "kmedoids = DFKMedoids(cluster_name='KMedoids', n_clusters=15, random_state=0,\n",
    "                      eval_inertia=True, eval_silhouette=True, eval_chi=True, eval_dbi=True)\n",
    "kmedoids.fit(ivis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(kmedoids.eval_df,\n",
    "        xy_tuples=[('n_cluster', x) for x in ['inertia', 'silhouette', 'calinski_harabasz', 'davies_bouldin']],\n",
    "        max_col=2,\n",
    "        title='Phase 10 - N Cluster - K-Medoids',\n",
    "        out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters by scores\n",
    "kmedoids.eval_df.loc[kmedoids.eval_df['silhouette'].idxmax()]['n_cluster'],\\\n",
    "kmedoids.eval_df.loc[kmedoids.eval_df['calinski_harabasz'].idxmax()]['n_cluster'],\\\n",
    "kmedoids.eval_df.loc[kmedoids.eval_df['davies_bouldin'].idxmin()]['n_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "kmedoids   = DFKMeans(cluster_name='KMedoids', n_clusters=6, random_state=0, n_jobs=-1)\n",
    "cluster_df = kmedoids.fit_predict(ivis_df)\n",
    "\n",
    "vp.value_count(cluster_df, 'KMedoids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = cluster_df.copy()\n",
    "tmp_df.sort_values(by='KMedoids', inplace=True)\n",
    "tmp_df['KMedoids'] = tmp_df['KMedoids'].astype(str)\n",
    "\n",
    "vp.scatter(tmp_df,\n",
    "           xy_tuples=[('ivis_0', 'ivis_1')],\n",
    "           color='KMedoids',\n",
    "           max_col=1,\n",
    "           title='Phase 10 - Scatter - K-Medoids',\n",
    "           out_path=OUT_PATH_GRAPH)\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['KMedoids']], data_df], axis=1)\n",
    "tmp_df['KMedoids'] = tmp_df['KMedoids'].astype(str)\n",
    "\n",
    "vp.box(tmp_df,\n",
    "       color='KMedoids',\n",
    "       max_col=2,\n",
    "       title='Phase 10 - Box - K-Medoids',\n",
    "       out_path=OUT_PATH_GRAPH,\n",
    "       layout_kwargs={\n",
    "           'showlegend': False,\n",
    "           'height': 1500\n",
    "       })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distribution Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['KMedoids']], data_df], axis=1)\n",
    "\n",
    "vp.distmat(tmp_df,\n",
    "           target='KMedoids',\n",
    "           title='Phase 10 - Distribution Matrix - K-Medoids',\n",
    "           out_path=OUT_PATH_GRAPH,\n",
    "           heatmap_kwargs={\n",
    "               'colorscale': 'Dense',\n",
    "               'zmin': 0,\n",
    "               'zmax': 1\n",
    "           })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
