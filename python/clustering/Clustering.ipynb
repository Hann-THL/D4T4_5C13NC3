{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib._util.visualplot as vp\n",
    "\n",
    "# Pre-processing\n",
    "from lib._class.DFDuplicateRemoval import DFDuplicateRemoval\n",
    "from lib._class.DFVarianceThreshold import DFVarianceThreshold\n",
    "from lib._class.DFVIFThreshold import DFVIFThreshold\n",
    "\n",
    "# Feature encoding\n",
    "from lib._class.DFOneHotEncoder import DFOneHotEncoder\n",
    "\n",
    "# Feature scaling\n",
    "from lib._class.DFStandardScaler import DFStandardScaler\n",
    "\n",
    "# Clustering\n",
    "from lib._class.DFKMeans import DFKMeans\n",
    "from lib._class.DFGaussianMixture import DFGaussianMixture\n",
    "from lib._class.DFAgglomerative import DFAgglomerative\n",
    "from lib._class.DFDBSCAN import DFDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH_DATA = 'resources/data/'\n",
    "OUT_PATH_GRAPH   = 'resources/output/graph/customer/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Data Loading\n",
    "- Reference: https://www.kaggle.com/fazilbtopal/popular-unsupervised-clustering-algorithms\n",
    "- CustomerID: Unique ID assigned to the customer\n",
    "- Gender: Gender of the customer\n",
    "- Age: Age of the customer\n",
    "- Annual Income (k$): Annual Income of the customee\n",
    "- Spending Score (1-100): Score assigned by the mall based on customer behavior and spending nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(f'{SOURCE_PATH_DATA}Mall_Customers.csv', sep=',')\n",
    "\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ID column\n",
    "data_df.drop(columns=['CustomerID'], inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "data_df.rename(columns={\n",
    "    'Annual Income (k$)': 'Income',\n",
    "    'Spending Score (1-100)': 'Score',\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.histogram(data_df,\n",
    "             bin_algo='count',\n",
    "             max_col=2,\n",
    "             title='Phase 1 - Histogram',\n",
    "             out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.box(data_df,\n",
    "       max_col=2,\n",
    "       title='Phase 1 - Box',\n",
    "       out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = data_df.copy()\n",
    "\n",
    "vp.pair(tmp_df,\n",
    "        color='Gender',\n",
    "        title='Phase 1 - Pair',\n",
    "        out_path=OUT_PATH_GRAPH)\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 - Data Preparation\n",
    "- Remove duplication\n",
    "- Feature scaling\n",
    "- Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df.copy()\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated data\n",
    "duplicate_removal = DFDuplicateRemoval()\n",
    "X = duplicate_removal.fit_transform(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_removal.duplicate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove low variance feature\n",
    "onehot_encoder     = DFOneHotEncoder(columns=X.select_dtypes(include='object').columns, dtype='byte', drop='first')\n",
    "variance_threshold = DFVarianceThreshold(threshold=.01)\n",
    "\n",
    "steps = [\n",
    "    ('onehot_encoder', onehot_encoder),\n",
    "    ('variance_threshold', variance_threshold),\n",
    "]\n",
    "X = Pipeline(steps).fit_transform(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_threshold.stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May choose to drop Male feature, as it's not useful in creating segmentation based on pair-plot\n",
    "standard_scaler = DFStandardScaler(columns=[x for x in data_df.columns if x != 'Gender_Male'])\n",
    "scale_df        = standard_scaler.fit_transform(X)\n",
    "\n",
    "scale_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "scale_df = DFVIFThreshold(show_progress=True).fit_transform(scale_df)\n",
    "\n",
    "scale_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(scale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 - Clustering\n",
    "- K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters\n",
    "kmeans = DFKMeans(cluster_name='KMeans_15', n_clusters=15, random_state=0, n_jobs=-1,\n",
    "                  eval_inertia=True, eval_silhouette=True, eval_chi=True, eval_dbi=True)\n",
    "kmeans.fit(scale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(kmeans.eval_df,\n",
    "        xy_tuples=[('n_cluster', x) for x in ['inertia', 'silhouette', 'calinski_harabasz', 'davies_bouldin']],\n",
    "        max_col=2,\n",
    "        title='Phase 3 - Cluster Evaluation - K-Means',\n",
    "        out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters by scores\n",
    "kmeans.eval_df.loc[kmeans.eval_df['silhouette'].idxmax()]['n_cluster'],\\\n",
    "kmeans.eval_df.loc[kmeans.eval_df['calinski_harabasz'].idxmax()]['n_cluster'],\\\n",
    "kmeans.eval_df.loc[kmeans.eval_df['davies_bouldin'].idxmin()]['n_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "kmeans     = DFKMeans(cluster_name='KMeans_6', n_clusters=6, random_state=0, n_jobs=-1)\n",
    "cluster_df = kmeans.fit_predict(scale_df)\n",
    "\n",
    "vp.value_count(cluster_df, 'KMeans_6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = cluster_df.copy()\n",
    "tmp_df.sort_values(by='KMeans_6', inplace=True)\n",
    "tmp_df['KMeans_6'] = tmp_df['KMeans_6'].astype(str)\n",
    "\n",
    "vp.pair(tmp_df,\n",
    "        color='KMeans_6',\n",
    "        title='Phase 3 - Pair - K-Means',\n",
    "        out_path=OUT_PATH_GRAPH)\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['KMeans_6']], data_df], axis=1)\n",
    "tmp_df['KMeans_6'] = tmp_df['KMeans_6'].astype(str)\n",
    "\n",
    "vp.box(tmp_df[[x for x in tmp_df.columns if x != 'Male']],\n",
    "       color='KMeans_6',\n",
    "       max_col=2,\n",
    "       title='Phase 3 - Box - K-Means',\n",
    "       out_path=OUT_PATH_GRAPH,\n",
    "       layout_kwargs={'showlegend': False})\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distribution Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['KMeans_6']], data_df], axis=1)\n",
    "\n",
    "vp.distmat(tmp_df,\n",
    "           target='KMeans_6',\n",
    "           title='Phase 3 - Distribution Matrix - K-Means',\n",
    "           out_path=OUT_PATH_GRAPH,\n",
    "           heatmap_kwargs={\n",
    "               'colorscale': 'Dense',\n",
    "               'zmin': 0,\n",
    "               'zmax': 1\n",
    "           })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4 - Clustering\n",
    "- Gaussian mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters\n",
    "gmm = DFGaussianMixture(cluster_name='GMM_15', n_components=15, random_state=0,\n",
    "                        eval_aic=True, eval_bic=True, eval_silhouette=True, eval_chi=True, eval_dbi=True)\n",
    "gmm.fit(scale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(gmm.eval_df,\n",
    "        xy_tuples=[('n_cluster', x) for x in ['akaike', 'bayesian', 'silhouette', 'calinski_harabasz', 'davies_bouldin']],\n",
    "        max_col=3,\n",
    "        title='Phase 4 - Cluster Evaluation - GMM',\n",
    "        out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters by scores\n",
    "gmm.eval_df.loc[gmm.eval_df[:7]['akaike'].idxmin()]['n_cluster'],\\\n",
    "gmm.eval_df.loc[gmm.eval_df['bayesian'].idxmin()]['n_cluster'],\\\n",
    "gmm.eval_df.loc[gmm.eval_df['silhouette'].idxmax()]['n_cluster'],\\\n",
    "gmm.eval_df.loc[gmm.eval_df[2:]['calinski_harabasz'].idxmax()]['n_cluster'],\\\n",
    "gmm.eval_df.loc[gmm.eval_df[:5]['davies_bouldin'].idxmin()]['n_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "gmm        = DFGaussianMixture(cluster_name='GMM_4', n_components=4, random_state=0)\n",
    "cluster_df = gmm.fit_predict(scale_df)\n",
    "\n",
    "vp.value_count(cluster_df, 'GMM_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = cluster_df.copy()\n",
    "tmp_df.sort_values(by='GMM_4', inplace=True)\n",
    "tmp_df['GMM_4'] = tmp_df['GMM_4'].astype(str)\n",
    "\n",
    "vp.pair(tmp_df,\n",
    "        color='GMM_4',\n",
    "        title='Phase 4 - Pair - GMM',\n",
    "        out_path=OUT_PATH_GRAPH)\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['GMM_4']], data_df], axis=1)\n",
    "tmp_df['GMM_4'] = tmp_df['GMM_4'].astype(str)\n",
    "\n",
    "vp.box(tmp_df,\n",
    "       color='GMM_4',\n",
    "       max_col=2,\n",
    "       title='Phase 4 - Box - GMM',\n",
    "       out_path=OUT_PATH_GRAPH,\n",
    "       layout_kwargs={'showlegend': False})\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distribution Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['GMM_4']], data_df], axis=1)\n",
    "\n",
    "vp.distmat(tmp_df,\n",
    "           target='GMM_4',\n",
    "           title='Phase 4 - Distribution Matrix - GMM',\n",
    "           out_path=OUT_PATH_GRAPH,\n",
    "           heatmap_kwargs={\n",
    "               'colorscale': 'Dense',\n",
    "               'zmin': 0,\n",
    "               'zmax': 1\n",
    "           })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5 - Clustering\n",
    "- Agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://stackabuse.com/hierarchical-clustering-with-python-and-scikit-learn/\n",
    "# Determine number of clusters\n",
    "agglo = DFAgglomerative(cluster_name='Agglo_15', n_clusters=15, random_state=0,\n",
    "                        eval_silhouette=True, eval_chi=True, eval_dbi=True)\n",
    "agglo.fit(scale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(agglo.eval_df,\n",
    "        xy_tuples=[('n_cluster', x) for x in ['silhouette', 'calinski_harabasz', 'davies_bouldin']],\n",
    "        max_col=2,\n",
    "        title='Phase 5 - Cluster Evaluation - Agglomerative',\n",
    "        out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.dendrogram(scale_df,\n",
    "              title='Phase 5 - Dendrogram - Agglomerative',\n",
    "              out_path=OUT_PATH_GRAPH,\n",
    "              layout_kwargs={\n",
    "                  'width': 1350,\n",
    "                  'height': 600\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters by scores\n",
    "agglo.eval_df.loc[agglo.eval_df['silhouette'].idxmax()]['n_cluster'],\\\n",
    "agglo.eval_df.loc[agglo.eval_df['calinski_harabasz'].idxmax()]['n_cluster'],\\\n",
    "agglo.eval_df.loc[agglo.eval_df['davies_bouldin'].idxmin()]['n_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "agglo      = DFAgglomerative(cluster_name='Agglo_6', n_clusters=6, random_state=0)\n",
    "cluster_df = agglo.fit_predict(scale_df)\n",
    "\n",
    "vp.value_count(cluster_df, 'Agglo_6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = cluster_df.copy()\n",
    "tmp_df.sort_values(by='Agglo_6', inplace=True)\n",
    "tmp_df['Agglo_6'] = tmp_df['Agglo_6'].astype(str)\n",
    "\n",
    "vp.pair(tmp_df,\n",
    "        color='Agglo_6',\n",
    "        title='Phase 5 - Pair - Agglomerative',\n",
    "        out_path=OUT_PATH_GRAPH)\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['Agglo_6']], data_df], axis=1)\n",
    "tmp_df['Agglo_6'] = tmp_df['Agglo_6'].astype(str)\n",
    "\n",
    "vp.box(tmp_df,\n",
    "       color='Agglo_6',\n",
    "       max_col=2,\n",
    "       title='Phase 5 - Box - Agglomerative',\n",
    "       out_path=OUT_PATH_GRAPH,\n",
    "       layout_kwargs={'showlegend': False})\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distribution Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['Agglo_6']], data_df], axis=1)\n",
    "\n",
    "vp.distmat(tmp_df,\n",
    "           target='Agglo_6',\n",
    "           title='Phase 5 - Distribution Matrix - Agglomerative',\n",
    "           out_path=OUT_PATH_GRAPH,\n",
    "           heatmap_kwargs={\n",
    "               'colorscale': 'Dense',\n",
    "               'zmin': 0,\n",
    "               'zmax': 1\n",
    "           })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 6 - Clustering\n",
    "- DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine hyperparameters with highest score\n",
    "dbscan = DFDBSCAN(cluster_name='DBSCAN', random_state=0, n_jobs=-1,\n",
    "                  eps_samples_tuples=[(round(x,5), 5) for x in np.arange(.1, 2, .1)],\n",
    "                  eval_cluster=True, eval_silhouette=True, eval_chi=True, eval_dbi=True)\n",
    "dbscan.fit(scale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(dbscan.eval_df,\n",
    "        xy_tuples=[('eps', x) for x in ['n_cluster', 'n_noise', 'silhouette', 'calinski_harabasz', 'davies_bouldin']],\n",
    "        max_col=3,\n",
    "        title='Phase 6 - EPS Evaluation - DBSCAN',\n",
    "        out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine EPS by scores\n",
    "dbscan.eval_df.loc[dbscan.eval_df['silhouette'].idxmax()]['eps'],\\\n",
    "dbscan.eval_df.loc[dbscan.eval_df['calinski_harabasz'].idxmax()]['eps'],\\\n",
    "dbscan.eval_df.loc[dbscan.eval_df['davies_bouldin'].idxmin()]['eps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "dbscan     = DFDBSCAN(cluster_name='DBSCAN', random_state=0, n_jobs=-1, eps=1.1, min_samples=5)\n",
    "cluster_df = dbscan.fit_predict(scale_df)\n",
    "\n",
    "vp.value_count(cluster_df, 'DBSCAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = cluster_df.copy()\n",
    "tmp_df.sort_values(by='DBSCAN', inplace=True)\n",
    "tmp_df['DBSCAN'] = tmp_df['DBSCAN'].astype(str)\n",
    "\n",
    "vp.pair(tmp_df,\n",
    "        color='DBSCAN',\n",
    "        title='Phase 6 - Pair - DBSCAN',\n",
    "        out_path=OUT_PATH_GRAPH)\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['DBSCAN']], data_df], axis=1)\n",
    "tmp_df['DBSCAN'] = tmp_df['DBSCAN'].astype(str)\n",
    "\n",
    "vp.box(tmp_df,\n",
    "       color='DBSCAN',\n",
    "       max_col=2,\n",
    "       title='Phase 6 - Box - DBSCAN',\n",
    "       out_path=OUT_PATH_GRAPH,\n",
    "       layout_kwargs={'showlegend': False})\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distribution Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([cluster_df[['DBSCAN']], data_df], axis=1)\n",
    "\n",
    "vp.distmat(tmp_df,\n",
    "           target='DBSCAN',\n",
    "           title='Phase 6 - Distribution Matrix - DBSCAN',\n",
    "           out_path=OUT_PATH_GRAPH,\n",
    "           heatmap_kwargs={\n",
    "               'colorscale': 'Dense',\n",
    "               'zmin': 0,\n",
    "               'zmax': 1\n",
    "           })\n",
    "\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
