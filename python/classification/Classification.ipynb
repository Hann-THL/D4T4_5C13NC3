{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib._util.visualplot as vp\n",
    "import lib._util.mlpipe as mlpipe\n",
    "\n",
    "# Pre-processing\n",
    "from lib._class.DFDuplicateRemoval import DFDuplicateRemoval\n",
    "\n",
    "# Feature scaling\n",
    "from lib._class.DFStandardScaler import DFStandardScaler\n",
    "from lib._class.DFMinMaxScaler import DFMinMaxScaler\n",
    "\n",
    "# Clustering\n",
    "from lib._class.DFKMeans import DFKMeans\n",
    "from lib._class.DFGaussianMixture import DFGaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# # Imbalanced-Learn\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "# Plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH_DATA = 'resources/data/'\n",
    "OUT_PATH_GRAPH   = 'resources/output/graph/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Data Loading\n",
    "- Reference: https://www.kaggle.com/mlg-ulb/creditcardfraud/home\n",
    "- Time: Number of seconds elapsed between this transaction and the first transaction in the dataset\n",
    "- V1-V28: May be result of a PCA dimensionality reduction to protect user identities and sensitive features\n",
    "- Amount: Transaction amount\n",
    "- Class: 1 for fraudulent transactions, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks = pd.read_csv(f'{SOURCE_PATH_DATA}creditcard.csv', sep=',', chunksize=50_000)\n",
    "data_df   = pd.concat(df_chunks)\n",
    "\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.histogram(data_df,\n",
    "             bin_algo='count',\n",
    "             max_col=4,\n",
    "             title='Phase 1 - Histogram',\n",
    "             out_path=OUT_PATH_GRAPH,\n",
    "             layout_kwargs={'height': 2048})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.box(data_df,\n",
    "       color='Class',\n",
    "       max_col=4,\n",
    "       title='Phase 1 - Box',\n",
    "       out_path=OUT_PATH_GRAPH,\n",
    "       layout_kwargs={\n",
    "           'height': 2048,\n",
    "           'legend_orientation': 'h'\n",
    "       })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.kde(data_df,\n",
    "       color='Class',\n",
    "       max_col=4,\n",
    "       title='Phase 1 - KDE',\n",
    "       out_path=OUT_PATH_GRAPH,\n",
    "       layout_kwargs={\n",
    "           'height': 2048,\n",
    "           'legend_orientation': 'h'\n",
    "       })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 - Data Preparation\n",
    "- Remove duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_removal = DFDuplicateRemoval(target='Class', keep='mean')\n",
    "duplicate_removal.fit(data_df)\n",
    "\n",
    "# Observe duplicated data\n",
    "duplicate_df = duplicate_removal.duplicate_df\n",
    "\n",
    "duplicate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(duplicate_df, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe if duplicated data are having different target label\n",
    "vp.value_count(\n",
    "    duplicate_df.groupby(duplicate_removal.subset).agg(\n",
    "        Class=('Class', 'mean')\n",
    "    ).reset_index(),\n",
    "    'Class'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated data\n",
    "data_df = duplicate_removal.transform(data_df)\n",
    "\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 - Classification\n",
    "- Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict = {\n",
    "    'weight_precision': [],\n",
    "    'weight_recall':    [],\n",
    "    'weight_f1':        [],\n",
    "    'roc_auc':          [],\n",
    "    'cv_score':         [],\n",
    "    'method':           [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features & target\n",
    "X, y = mlpipe.xy_split(data_df, 'Class')\n",
    "\n",
    "vp.value_count(y.to_frame(), 'Class')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate dataset\n",
    "X_train, X_test, y_train, y_test = mlpipe.dataset_split(X, y, test_size=.3, stratify=y, random_state=0)\n",
    "\n",
    "print('Train dataset:\\n-----------------------')\n",
    "vp.value_count(y_train.to_frame(), 'Class')\n",
    "print('\\nTest dataset:\\n----------------------')\n",
    "vp.value_count(y_test.to_frame(), 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score\n",
    "standard_scaler = DFStandardScaler(columns=['Time', 'Amount'])\n",
    "minmax_scaler   = DFMinMaxScaler()\n",
    "\n",
    "steps = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "]\n",
    "pipeline = Pipeline(steps, verbose=True)\n",
    "pipeline.fit(X_train)\n",
    "\n",
    "model  = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    pipeline.transform(X_train),\n",
    "    y_train,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(10),\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f'Mean score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    pipeline.transform(X_train),\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Evaluate train data\n",
    "mlpipe.eval_classif(\n",
    "    y_train,\n",
    "    model.predict(\n",
    "        pipeline.transform(X_train)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(X_train)\n",
    "    )[:,-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data\n",
    "eval_dict = mlpipe.eval_classif(\n",
    "    y_test,\n",
    "    model.predict(\n",
    "        pipeline.transform(X_test)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(X_test)\n",
    "    )[:,-1],\n",
    "    return_evaluation=True\n",
    ")\n",
    "\n",
    "metric_dict['method'].append('Baseline')\n",
    "metric_dict['cv_score'].append(scores)\n",
    "metric_dict['roc_auc'].append(eval_dict['roc_auc'])\n",
    "metric_dict['weight_precision'].append(eval_dict['report']['weighted avg']['precision'])\n",
    "metric_dict['weight_recall'].append(eval_dict['report']['weighted avg']['recall'])\n",
    "metric_dict['weight_f1'].append(eval_dict['report']['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4 - Classification\n",
    "- Class Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes           = np.unique(y_train)\n",
    "weights           = compute_class_weight('balanced', classes, y_train)\n",
    "class_weight_dict = {classes[i]: x for i,x in enumerate(weights)}\n",
    "\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score\n",
    "steps = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "]\n",
    "pipeline = Pipeline(steps, verbose=True)\n",
    "pipeline.fit(X_train)\n",
    "\n",
    "model  = LogisticRegression(class_weight=class_weight_dict, random_state=0, n_jobs=-1)\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    pipeline.transform(X_train),\n",
    "    y_train,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(10),\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f'Mean score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    pipeline.transform(X_train),\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Evaluate train data\n",
    "mlpipe.eval_classif(\n",
    "    y_train,\n",
    "    model.predict(\n",
    "        pipeline.transform(X_train)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(X_train)\n",
    "    )[:,-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data\n",
    "eval_dict = mlpipe.eval_classif(\n",
    "    y_test,\n",
    "    model.predict(\n",
    "        pipeline.transform(X_test)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(X_test)\n",
    "    )[:,-1],\n",
    "    return_evaluation=True\n",
    ")\n",
    "\n",
    "metric_dict['method'].append('Class Weight')\n",
    "metric_dict['cv_score'].append(scores)\n",
    "metric_dict['roc_auc'].append(eval_dict['roc_auc'])\n",
    "metric_dict['weight_precision'].append(eval_dict['report']['weighted avg']['precision'])\n",
    "metric_dict['weight_recall'].append(eval_dict['report']['weighted avg']['recall'])\n",
    "metric_dict['weight_f1'].append(eval_dict['report']['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference:\n",
    "# - https://machinelearningmastery.com/cost-sensitive-neural-network-for-imbalanced-classification/?fbclid=IwAR1PcEicqDXadG9hsNE-Tf4RQQ_DpIaCV4LRcuizGbTC9Ek5PiMbB_x26bU\n",
    "# - https://www.youtube.com/watch?v=D6AChZlN5m0\n",
    "n_class0          = y_train.value_counts().loc[0]\n",
    "n_class1          = y_train.value_counts().loc[1]\n",
    "class_weight_dict = {0: 1, 1: int(round(n_class0 / n_class1))}\n",
    "\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score\n",
    "steps = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "]\n",
    "pipeline = Pipeline(steps, verbose=True)\n",
    "pipeline.fit(X_train)\n",
    "\n",
    "model  = LogisticRegression(class_weight=class_weight_dict, random_state=0, n_jobs=-1)\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    pipeline.transform(X_train),\n",
    "    y_train,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(10),\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f'Mean score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    pipeline.transform(X_train),\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Evaluate train data\n",
    "mlpipe.eval_classif(\n",
    "    y_train,\n",
    "    model.predict(\n",
    "        pipeline.transform(X_train)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(X_train)\n",
    "    )[:,-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data\n",
    "eval_dict = mlpipe.eval_classif(\n",
    "    y_test,\n",
    "    model.predict(\n",
    "        pipeline.transform(X_test)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(X_test)\n",
    "    )[:,-1],\n",
    "    return_evaluation=True\n",
    ")\n",
    "\n",
    "metric_dict['method'].append('Class Ratio')\n",
    "metric_dict['cv_score'].append(scores)\n",
    "metric_dict['roc_auc'].append(eval_dict['roc_auc'])\n",
    "metric_dict['weight_precision'].append(eval_dict['report']['weighted avg']['precision'])\n",
    "metric_dict['weight_recall'].append(eval_dict['report']['weighted avg']['recall'])\n",
    "metric_dict['weight_f1'].append(eval_dict['report']['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5 - Classification\n",
    "- Re-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE + ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('smote_enn', SMOTEENN(random_state=0, n_jobs=-1)),\n",
    "]\n",
    "X_bal, y_bal = Pipeline(steps, verbose=True).fit_resample(X_train, y_train)\n",
    "\n",
    "vp.value_count(y_bal.to_frame(), 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score\n",
    "steps = [\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "]\n",
    "pipeline = Pipeline(steps, verbose=True)\n",
    "pipeline.fit(X_bal)\n",
    "\n",
    "model  = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    pipeline.transform(X_bal),\n",
    "    y_bal,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(10),\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f'Mean score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    pipeline.transform(X_bal),\n",
    "    y_bal\n",
    ")\n",
    "\n",
    "# Evaluate train data (re-sample)\n",
    "mlpipe.eval_classif(\n",
    "    y_bal,\n",
    "    model.predict(\n",
    "        pipeline.transform(X_bal)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(X_bal)\n",
    "    )[:,-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate train data (original)\n",
    "steps = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "]\n",
    "\n",
    "mlpipe.eval_classif(\n",
    "    y_train,\n",
    "    model.predict(\n",
    "        Pipeline(steps, verbose=True).transform(X_train)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        Pipeline(steps, verbose=True).transform(X_train)\n",
    "    )[:,-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data\n",
    "steps = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "]\n",
    "\n",
    "eval_dict = mlpipe.eval_classif(\n",
    "    y_test,\n",
    "    model.predict(\n",
    "        Pipeline(steps, verbose=True).transform(X_test)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        Pipeline(steps, verbose=True).transform(X_test)\n",
    "    )[:,-1],\n",
    "    return_evaluation=True\n",
    ")\n",
    "\n",
    "metric_dict['method'].append('SMOTE + ENN')\n",
    "metric_dict['cv_score'].append(scores)\n",
    "metric_dict['roc_auc'].append(eval_dict['roc_auc'])\n",
    "metric_dict['weight_precision'].append(eval_dict['report']['weighted avg']['precision'])\n",
    "metric_dict['weight_recall'].append(eval_dict['report']['weighted avg']['recall'])\n",
    "metric_dict['weight_f1'].append(eval_dict['report']['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE + Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('smote_tomek', SMOTETomek(random_state=0, n_jobs=-1)),\n",
    "]\n",
    "X_bal, y_bal = Pipeline(steps, verbose=True).fit_resample(X_train, y_train)\n",
    "\n",
    "vp.value_count(y_bal.to_frame(), 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score\n",
    "steps = [\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "]\n",
    "pipeline = Pipeline(steps, verbose=True)\n",
    "pipeline.fit(X_bal)\n",
    "\n",
    "model  = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    pipeline.transform(X_bal),\n",
    "    y_bal,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(10),\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f'Mean score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    pipeline.transform(X_bal),\n",
    "    y_bal\n",
    ")\n",
    "\n",
    "# Evaluate train data (re-sample)\n",
    "mlpipe.eval_classif(\n",
    "    y_bal,\n",
    "    model.predict(\n",
    "        pipeline.transform(X_bal)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(X_bal)\n",
    "    )[:,-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate train data (original)\n",
    "steps = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "]\n",
    "\n",
    "mlpipe.eval_classif(\n",
    "    y_train,\n",
    "    model.predict(\n",
    "        Pipeline(steps, verbose=True).transform(X_train)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        Pipeline(steps, verbose=True).transform(X_train)\n",
    "    )[:,-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data\n",
    "steps = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "]\n",
    "\n",
    "eval_dict = mlpipe.eval_classif(\n",
    "    y_test,\n",
    "    model.predict(\n",
    "        Pipeline(steps, verbose=True).transform(X_test)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        Pipeline(steps, verbose=True).transform(X_test)\n",
    "    )[:,-1],\n",
    "    return_evaluation=True\n",
    ")\n",
    "\n",
    "metric_dict['method'].append('SMOTE + Tomek')\n",
    "metric_dict['cv_score'].append(scores)\n",
    "metric_dict['roc_auc'].append(eval_dict['roc_auc'])\n",
    "metric_dict['weight_precision'].append(eval_dict['report']['weighted avg']['precision'])\n",
    "metric_dict['weight_recall'].append(eval_dict['report']['weighted avg']['recall'])\n",
    "metric_dict['weight_f1'].append(eval_dict['report']['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 6 - Classification\n",
    "- Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters\n",
    "kmeans = DFKMeans(cluster_name='KMeans', n_clusters=15, random_state=0, n_jobs=-1,\n",
    "                  eval_inertia=True, eval_silhouette=True, eval_chi=True, eval_dbi=True,\n",
    "                  eval_sample_size=int(len(X_train) * .25))\n",
    "\n",
    "steps = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('kmeans', kmeans),\n",
    "]\n",
    "Pipeline(steps, verbose=True).fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(kmeans.eval_df,\n",
    "        xy_tuples=[('n_cluster', x) for x in ['inertia', 'silhouette', 'calinski_harabasz', 'davies_bouldin']],\n",
    "        max_col=2,\n",
    "        title='Phase 6 - N Cluster - K-Means',\n",
    "        out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters by scores\n",
    "kmeans.eval_df.loc[kmeans.eval_df['silhouette'].idxmax()]['n_cluster'],\\\n",
    "kmeans.eval_df.loc[kmeans.eval_df['calinski_harabasz'].idxmax()]['n_cluster'],\\\n",
    "kmeans.eval_df.loc[kmeans.eval_df['davies_bouldin'].idxmin()]['n_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "kmeans = DFKMeans(cluster_name='KMeans', n_clusters=5, random_state=0, n_jobs=-1)\n",
    "\n",
    "steps  = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('kmeans', kmeans),\n",
    "]\n",
    "cluster_pipeline = Pipeline(steps, verbose=True).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes           = np.unique(y_train)\n",
    "weights           = compute_class_weight('balanced', classes, y_train)\n",
    "class_weight_dict = {classes[i]: x for i,x in enumerate(weights)}\n",
    "\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score\n",
    "steps = [\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "]\n",
    "pipeline = Pipeline(steps, verbose=True)\n",
    "pipeline.fit(\n",
    "    cluster_pipeline.predict_proba(X_train)\n",
    ")\n",
    "\n",
    "model  = LogisticRegression(class_weight=class_weight_dict, random_state=0, n_jobs=-1)\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    pipeline.transform(\n",
    "        cluster_pipeline.predict_proba(X_train)\n",
    "    ),\n",
    "    y_train,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(10),\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f'Mean score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    pipeline.transform(\n",
    "        cluster_pipeline.predict_proba(X_train)\n",
    "    ),\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Evaluate train data\n",
    "mlpipe.eval_classif(\n",
    "    y_train,\n",
    "    model.predict(\n",
    "        pipeline.transform(\n",
    "            cluster_pipeline.predict_proba(X_train)\n",
    "        )\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(\n",
    "            cluster_pipeline.predict_proba(X_train)\n",
    "        )\n",
    "    )[:,-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data\n",
    "eval_dict = mlpipe.eval_classif(\n",
    "    y_test,\n",
    "    model.predict(\n",
    "        pipeline.transform(\n",
    "            cluster_pipeline.predict_proba(X_test)\n",
    "        )\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(\n",
    "            cluster_pipeline.predict_proba(X_test)\n",
    "        )\n",
    "    )[:,-1],\n",
    "    return_evaluation=True\n",
    ")\n",
    "\n",
    "metric_dict['method'].append('K-Means')\n",
    "metric_dict['cv_score'].append(scores)\n",
    "metric_dict['roc_auc'].append(eval_dict['roc_auc'])\n",
    "metric_dict['weight_precision'].append(eval_dict['report']['weighted avg']['precision'])\n",
    "metric_dict['weight_recall'].append(eval_dict['report']['weighted avg']['recall'])\n",
    "metric_dict['weight_f1'].append(eval_dict['report']['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters\n",
    "gmm = DFGaussianMixture(cluster_name='GMM', n_components=15, max_iter=1_000, random_state=0,\n",
    "                        eval_aic=True, eval_bic=True, eval_silhouette=True, eval_chi=True, eval_dbi=True,\n",
    "                        eval_sample_size=int(len(X_train) * .25))\n",
    "\n",
    "steps = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('gmm', gmm),\n",
    "]\n",
    "Pipeline(steps, verbose=True).fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.line(gmm.eval_df,\n",
    "        xy_tuples=[('n_cluster', x) for x in ['akaike', 'bayesian', 'silhouette', 'calinski_harabasz', 'davies_bouldin']],\n",
    "        max_col=3,\n",
    "        title='Phase 6 - N Cluster - GMM',\n",
    "        out_path=OUT_PATH_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of clusters by scores\n",
    "gmm.eval_df.loc[gmm.eval_df['akaike'].idxmin()]['n_cluster'],\\\n",
    "gmm.eval_df.loc[gmm.eval_df['bayesian'].idxmin()]['n_cluster'],\\\n",
    "gmm.eval_df.loc[gmm.eval_df['silhouette'].idxmax()]['n_cluster'],\\\n",
    "gmm.eval_df.loc[gmm.eval_df['calinski_harabasz'].idxmax()]['n_cluster'],\\\n",
    "gmm.eval_df.loc[gmm.eval_df['davies_bouldin'].idxmin()]['n_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "gmm = DFGaussianMixture(cluster_name='GMM', n_components=3, max_iter=1_000, random_state=0)\n",
    "\n",
    "steps  = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('gmm', gmm),\n",
    "]\n",
    "cluster_pipeline = Pipeline(steps, verbose=True).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes           = np.unique(y_train)\n",
    "weights           = compute_class_weight('balanced', classes, y_train)\n",
    "class_weight_dict = {classes[i]: x for i,x in enumerate(weights)}\n",
    "\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score\n",
    "steps = [\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "]\n",
    "pipeline = Pipeline(steps, verbose=True)\n",
    "pipeline.fit(\n",
    "    cluster_pipeline.predict_proba(X_train)\n",
    ")\n",
    "\n",
    "model  = LogisticRegression(class_weight=class_weight_dict, random_state=0, n_jobs=-1)\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    pipeline.transform(\n",
    "        cluster_pipeline.predict_proba(X_train)\n",
    "    ),\n",
    "    y_train,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(10),\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f'Mean score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    pipeline.transform(\n",
    "        cluster_pipeline.predict_proba(X_train)\n",
    "    ),\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Evaluate train data\n",
    "mlpipe.eval_classif(\n",
    "    y_train,\n",
    "    model.predict(\n",
    "        pipeline.transform(\n",
    "            cluster_pipeline.predict_proba(X_train)\n",
    "        )\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(\n",
    "            cluster_pipeline.predict_proba(X_train)\n",
    "        )\n",
    "    )[:,-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data\n",
    "eval_dict = mlpipe.eval_classif(\n",
    "    y_test,\n",
    "    model.predict(\n",
    "        pipeline.transform(\n",
    "            cluster_pipeline.predict_proba(X_test)\n",
    "        )\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(\n",
    "            cluster_pipeline.predict_proba(X_test)\n",
    "        )\n",
    "    )[:,-1],\n",
    "    return_evaluation=True\n",
    ")\n",
    "\n",
    "metric_dict['method'].append('GMM')\n",
    "metric_dict['cv_score'].append(scores)\n",
    "metric_dict['roc_auc'].append(eval_dict['roc_auc'])\n",
    "metric_dict['weight_precision'].append(eval_dict['report']['weighted avg']['precision'])\n",
    "metric_dict['weight_recall'].append(eval_dict['report']['weighted avg']['recall'])\n",
    "metric_dict['weight_f1'].append(eval_dict['report']['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 7 - Classification\n",
    "- Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes           = np.unique(y_train)\n",
    "weights           = compute_class_weight('balanced', classes, y_train)\n",
    "class_weight_dict = {classes[i]: x for i,x in enumerate(weights)}\n",
    "\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://towardsdatascience.com/logistic-regression-model-tuning-with-scikit-learn-part-1-425142e01af5\n",
    "model  = LogisticRegression(class_weight=class_weight_dict, random_state=0, n_jobs=-1)\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions={\n",
    "        'C': np.logspace(-4, 4, 20),\n",
    "        'penalty': ['l1', 'l2'],\n",
    "    },\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(n_splits=10),\n",
    "    n_jobs=-1,\n",
    "    verbose=10,\n",
    "    n_iter=100,\n",
    "    random_state=0\n",
    ")\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(search.cv_results_)\n",
    "result_df[['params', 'mean_test_score', 'rank_test_score']].sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score\n",
    "steps = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "]\n",
    "pipeline = Pipeline(steps, verbose=True)\n",
    "pipeline.fit(X_train)\n",
    "\n",
    "model  = LogisticRegression(**search.best_params_, class_weight=class_weight_dict, random_state=0, n_jobs=-1)\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    pipeline.transform(X_train),\n",
    "    y_train,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(10),\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f'Mean score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    pipeline.transform(X_train),\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Evaluate train data\n",
    "mlpipe.eval_classif(\n",
    "    y_train,\n",
    "    model.predict(\n",
    "        pipeline.transform(X_train)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(X_train)\n",
    "    )[:,-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data\n",
    "eval_dict = mlpipe.eval_classif(\n",
    "    y_test,\n",
    "    model.predict(\n",
    "        pipeline.transform(X_test)\n",
    "    ),\n",
    "    y_prob=model.predict_proba(\n",
    "        pipeline.transform(X_test)\n",
    "    )[:,-1],\n",
    "    return_evaluation=True\n",
    ")\n",
    "\n",
    "metric_dict['method'].append('CV Search')\n",
    "metric_dict['cv_score'].append(scores)\n",
    "metric_dict['roc_auc'].append(eval_dict['roc_auc'])\n",
    "metric_dict['weight_precision'].append(eval_dict['report']['weighted avg']['precision'])\n",
    "metric_dict['weight_recall'].append(eval_dict['report']['weighted avg']['recall'])\n",
    "metric_dict['weight_f1'].append(eval_dict['report']['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df  = pd.DataFrame(metric_dict)\n",
    "eval_df['cv_mean'] = eval_df['cv_score'].apply(np.mean)\n",
    "\n",
    "metrics  = [x for x in eval_df.columns if x not in ['cv_score', 'method']]\n",
    "eval_dfs = [eval_df[[x, 'method']].rename(columns={x: 'score'}) for x in metrics]\n",
    "for i,x in enumerate(eval_dfs):\n",
    "    x['metric'] = metrics[i]\n",
    "\n",
    "fig = px.bar(\n",
    "    pd.concat(eval_dfs, axis=0),\n",
    "    x='metric',\n",
    "    y='score',\n",
    "    color='method',\n",
    "    barmode='group'\n",
    ")\n",
    "fig['layout']['legend_orientation'] = 'h'\n",
    "\n",
    "vp.generate_plot(\n",
    "    fig,\n",
    "    out_path=OUT_PATH_GRAPH,\n",
    "    out_filename='Phase 7 - Bar - Metrics Comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 8 - Classification\n",
    "- Stack Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
