{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib._util.visualplot as vp\n",
    "import lib._util.mlpipe as mlpipe\n",
    "\n",
    "# Pre-processing\n",
    "from lib._class.DFDuplicateRemoval import DFDuplicateRemoval\n",
    "\n",
    "# Feature scaling\n",
    "from lib._class.DFStandardScaler import DFStandardScaler\n",
    "from lib._class.DFMinMaxScaler import DFMinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Imbalanced-Learn\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.over_sampling import ADASYN, BorderlineSMOTE, SVMSMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, TomekLinks\n",
    "\n",
    "# Plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH_DATA = 'resources/data/'\n",
    "OUT_PATH_GRAPH   = 'resources/output/graph/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Data Loading\n",
    "- Reference: https://www.kaggle.com/mlg-ulb/creditcardfraud/home\n",
    "- Time: Number of seconds elapsed between this transaction and the first transaction in the dataset\n",
    "- V1-V28: May be result of a PCA dimensionality reduction to protect user identities and sensitive features\n",
    "- Amount: Transaction amount\n",
    "- Class: 1 for fraudulent transactions, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks = pd.read_csv(f'{SOURCE_PATH_DATA}creditcard.csv', sep=',', chunksize=50_000)\n",
    "data_df   = pd.concat(df_chunks)\n",
    "\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.faststat(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.histogram(data_df,\n",
    "             bin_algo='count',\n",
    "             max_col=4,\n",
    "             title='Phase 1 - Histogram',\n",
    "             out_path=OUT_PATH_GRAPH,\n",
    "             layout_kwargs={'height': 2048})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.box(data_df,\n",
    "       color='Class',\n",
    "       max_col=4,\n",
    "       title='Phase 1 - Box',\n",
    "       out_path=OUT_PATH_GRAPH,\n",
    "       layout_kwargs={\n",
    "           'height': 2048,\n",
    "           'legend_orientation': 'h'\n",
    "       })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.kde(data_df,\n",
    "       color='Class',\n",
    "       max_col=4,\n",
    "       title='Phase 1 - KDE',\n",
    "       out_path=OUT_PATH_GRAPH,\n",
    "       layout_kwargs={\n",
    "           'height': 2048,\n",
    "           'legend_orientation': 'h'\n",
    "       })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 - Data Preparation\n",
    "- Remove duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_removal = DFDuplicateRemoval(target='Class', keep='mean')\n",
    "duplicate_removal.fit(data_df)\n",
    "\n",
    "# Observe duplicated data\n",
    "duplicate_df = duplicate_removal.duplicate_df\n",
    "\n",
    "duplicate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(duplicate_df, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe if duplicated data are having different target label\n",
    "vp.value_count(\n",
    "    duplicate_df.groupby(duplicate_removal.subset).agg(\n",
    "        Class=('Class', 'mean')\n",
    "    ).reset_index(),\n",
    "    'Class'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated data\n",
    "data_df = duplicate_removal.transform(data_df)\n",
    "\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.value_count(data_df, 'Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 - Classification\n",
    "- Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict = {\n",
    "    'macro_precision': [],\n",
    "    'macro_recall':    [],\n",
    "    'macro_f1':        [],\n",
    "    'roc_auc':         [],\n",
    "    'pr_auc':          [],\n",
    "    'cv_score':        [],\n",
    "    'method':          [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features & target\n",
    "X, y = mlpipe.xy_split(data_df, 'Class')\n",
    "\n",
    "vp.value_count(y.to_frame(), 'Class')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate dataset\n",
    "X_train, X_test, y_train, y_test = mlpipe.dataset_split(X, y, test_size=.3, stratify=y, random_state=0)\n",
    "\n",
    "print('Train dataset:\\n-----------------------')\n",
    "vp.value_count(y_train.to_frame(), 'Class')\n",
    "print('\\nTest dataset:\\n----------------------')\n",
    "vp.value_count(y_test.to_frame(), 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(estimator, X, y):\n",
    "    return cross_val_score(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        scoring='roc_auc',\n",
    "        cv=StratifiedKFold(10),\n",
    "        verbose=10,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "def train_test_evaluation(method, metric_dict, cv_scores,\n",
    "                          model, X_train, y_train, X_test, y_test,\n",
    "                          train_pipeline, test_pipeline=None):\n",
    "    \n",
    "    # Model training\n",
    "    model.fit(\n",
    "        train_pipeline.fit_transform(X_train),\n",
    "        y_train\n",
    "    )\n",
    "\n",
    "    # Evaluate test data\n",
    "    test_pipeline = train_pipeline if test_pipeline is None else test_pipeline\n",
    "    \n",
    "    eval_dict = mlpipe.eval_classif(\n",
    "        y_test,\n",
    "        model.predict(\n",
    "            test_pipeline.transform(X_test)\n",
    "        ),\n",
    "        y_prob=model.predict_proba(\n",
    "            test_pipeline.transform(X_test)\n",
    "        )[:,-1],\n",
    "        return_evaluation=True\n",
    "    )\n",
    "\n",
    "    metric_dict['method'].append(method)\n",
    "    metric_dict['cv_score'].append(cv_scores)\n",
    "    metric_dict['roc_auc'].append(eval_dict['roc_auc'])\n",
    "    metric_dict['pr_auc'].append(eval_dict['pr_auc'])\n",
    "    metric_dict['macro_precision'].append(eval_dict['report']['macro avg']['precision'])\n",
    "    metric_dict['macro_recall'].append(eval_dict['report']['macro avg']['recall'])\n",
    "    metric_dict['macro_f1'].append(eval_dict['report']['macro avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = DFStandardScaler(columns=['Time', 'Amount'])\n",
    "minmax_scaler   = DFMinMaxScaler()\n",
    "model           = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "\n",
    "# Cross validation\n",
    "scores = cross_validation(\n",
    "    Pipeline(steps=[\n",
    "        ('standard_scaler', standard_scaler),\n",
    "        ('minmax_scaler', minmax_scaler),\n",
    "        ('model', model),\n",
    "    ], verbose=True),\n",
    "    X_train,\n",
    "    y_train\n",
    ")\n",
    "print(f'CV Score: {np.mean(scores) :.5f} ({np.std(scores) :.5f})\\n')\n",
    "\n",
    "# Evaluation\n",
    "train_test_evaluation(\n",
    "    'Baseline',\n",
    "    metric_dict,\n",
    "    scores,\n",
    "    model,\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    train_pipeline=Pipeline(steps=[\n",
    "        ('standard_scaler', standard_scaler),\n",
    "        ('minmax_scaler', minmax_scaler),\n",
    "    ], verbose=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4 - Classification\n",
    "- Class Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weight(y, normalize=False):\n",
    "    classes     = np.unique(y)\n",
    "    weights     = compute_class_weight('balanced', classes, y)\n",
    "    weight_dict = {classes[i]: x for i,x in enumerate(weights)}\n",
    "    \n",
    "    if normalize:\n",
    "        return {k: v / np.sum(list(weight_dict.values())) for k,v in weight_dict.items()}\n",
    "    return weight_dict\n",
    "\n",
    "# Reference:\n",
    "# - https://machinelearningmastery.com/cost-sensitive-neural-network-for-imbalanced-classification/?fbclid=IwAR1PcEicqDXadG9hsNE-Tf4RQQ_DpIaCV4LRcuizGbTC9Ek5PiMbB_x26bU\n",
    "# - https://www.youtube.com/watch?v=D6AChZlN5m0\n",
    "def class_ratio(y, rounding=None, normalize=False):\n",
    "    roundings = [None, 'round', 'ceil', 'floor']\n",
    "    assert rounding in roundings, f'rounding not in valid list: {roundings}'\n",
    "    \n",
    "    n_class0 = y.value_counts().loc[0]\n",
    "    n_class1 = y.value_counts().loc[1]\n",
    "    \n",
    "    if rounding == 'round':\n",
    "        weight_dict = {0: 1, 1: int(np.round(n_class0 / n_class1))}\n",
    "    elif rounding == 'ceil':\n",
    "        weight_dict = {0: 1, 1: int(np.ceil(n_class0 / n_class1))}\n",
    "    elif rounding == 'floor':\n",
    "        weight_dict = {0: 1, 1: int(np.floor(n_class0 / n_class1))}\n",
    "    else:\n",
    "        weight_dict = {0: 1, 1: n_class0 / n_class1}\n",
    "    \n",
    "    if normalize:\n",
    "        return {k: v / np.sum(list(weight_dict.values())) for k,v in weight_dict.items()}\n",
    "    return weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [\n",
    "    ('Class Weight', class_weight(y_train)),\n",
    "    ('Class Weight (Normalize)', class_weight(y_train, normalize=True)),\n",
    "    ('Class Ratio', class_ratio(y_train)),\n",
    "    ('Class Ratio (Normalize)', class_ratio(y_train, normalize=True)),\n",
    "    ('Class Ratio Floor', class_ratio(y_train, rounding='floor')),\n",
    "    ('Class Ratio Floor (Normalize)', class_ratio(y_train, rounding='floor', normalize=True)),\n",
    "    ('Class Ratio Ceil', class_ratio(y_train, rounding='ceil')),\n",
    "    ('Class Ratio Ceil (Normalize)', class_ratio(y_train, rounding='ceil', normalize=True)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for method, class_weight_dict in class_weights:\n",
    "    print(f'\\n{method}:')\n",
    "    \n",
    "    model = LogisticRegression(class_weight=class_weight_dict, random_state=0, n_jobs=-1)\n",
    "    \n",
    "    # Cross validation\n",
    "    scores = cross_validation(\n",
    "        Pipeline(steps=[\n",
    "            ('standard_scaler', standard_scaler),\n",
    "            ('minmax_scaler', minmax_scaler),\n",
    "            ('model', model),\n",
    "        ], verbose=True),\n",
    "        X_train,\n",
    "        y_train\n",
    "    )\n",
    "    print(f'CV Score: {np.mean(scores) :.5f} ({np.std(scores) :.5f})\\n')\n",
    "\n",
    "    # Evaluation\n",
    "    train_test_evaluation(\n",
    "        method,\n",
    "        metric_dict,\n",
    "        scores,\n",
    "        model,\n",
    "        X_train, y_train, X_test, y_test,\n",
    "        train_pipeline=Pipeline(steps=[\n",
    "            ('standard_scaler', standard_scaler),\n",
    "            ('minmax_scaler', minmax_scaler),\n",
    "        ], verbose=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5 - Classification\n",
    "- Re-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [\n",
    "    (\n",
    "        'ADASYN + ENN',\n",
    "        Pipeline(steps=[\n",
    "            ('standard_scaler', standard_scaler),\n",
    "            ('adasyn', ADASYN(random_state=0, n_jobs=-1)),\n",
    "            ('enn', EditedNearestNeighbours(n_jobs=-1, sampling_strategy='all')),\n",
    "        ], verbose=True)\n",
    "    ),\n",
    "    (\n",
    "        'ADASYN + Tomek',\n",
    "        Pipeline(steps=[\n",
    "            ('standard_scaler', standard_scaler),\n",
    "            ('adasyn', ADASYN(random_state=0, n_jobs=-1)),\n",
    "            ('tomek', TomekLinks(n_jobs=-1, sampling_strategy='all')),\n",
    "        ], verbose=True)\n",
    "    ),\n",
    "    (\n",
    "        'SMOTE + ENN',\n",
    "        Pipeline(steps=[\n",
    "            ('standard_scaler', standard_scaler),\n",
    "            ('smote_enn', SMOTEENN(random_state=0, n_jobs=-1)),\n",
    "        ], verbose=True)\n",
    "    ),\n",
    "    (\n",
    "        'SMOTE + Tomek',\n",
    "        Pipeline(steps=[\n",
    "            ('standard_scaler', standard_scaler),\n",
    "            ('smote_tomek', SMOTETomek(random_state=0, n_jobs=-1)),\n",
    "        ], verbose=True)\n",
    "    ),\n",
    "    (\n",
    "        'Borderline SMOTE + ENN',\n",
    "        Pipeline(steps=[\n",
    "            ('standard_scaler', standard_scaler),\n",
    "            ('borderline_smote', BorderlineSMOTE(random_state=0, n_jobs=-1)),\n",
    "            ('enn', EditedNearestNeighbours(n_jobs=-1, sampling_strategy='all')),\n",
    "        ], verbose=True)\n",
    "    ),\n",
    "    (\n",
    "        'Borderline SMOTE + Tomek',\n",
    "        Pipeline(steps=[\n",
    "            ('standard_scaler', standard_scaler),\n",
    "            ('borderline_smote', BorderlineSMOTE(random_state=0, n_jobs=-1)),\n",
    "            ('tomek', TomekLinks(n_jobs=-1, sampling_strategy='all')),\n",
    "        ], verbose=True)\n",
    "    ),\n",
    "    (\n",
    "        'SVM SMOTE + ENN',\n",
    "        Pipeline(steps=[\n",
    "            ('standard_scaler', standard_scaler),\n",
    "            ('svm_smote', SVMSMOTE(random_state=0, n_jobs=-1)),\n",
    "            ('enn', EditedNearestNeighbours(n_jobs=-1, sampling_strategy='all')),\n",
    "        ], verbose=True)\n",
    "    ),\n",
    "    (\n",
    "        'SVM SMOTE + Tomek',\n",
    "        Pipeline(steps=[\n",
    "            ('standard_scaler', standard_scaler),\n",
    "            ('svm_smote', SVMSMOTE(random_state=0, n_jobs=-1)),\n",
    "            ('tomek', TomekLinks(n_jobs=-1, sampling_strategy='all')),\n",
    "        ], verbose=True)\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for method, resample_pipeline in pipelines:\n",
    "    print(f'\\n{method}:')\n",
    "    \n",
    "    # Cross validation\n",
    "    model  = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "    steps = resample_pipeline.steps.copy()\n",
    "    steps.append(('minmax_scaler', minmax_scaler))\n",
    "    steps.append(('model', model))\n",
    "    pipeline = Pipeline(steps, verbose=True)\n",
    "\n",
    "    # Reference: https://kiwidamien.github.io/how-to-do-cross-validation-when-upsampling-data.html\n",
    "    scores = cross_validation(\n",
    "        pipeline,\n",
    "        X_train,\n",
    "        y_train\n",
    "    )\n",
    "    print(f'CV Score: {np.mean(scores) :.5f} ({np.std(scores) :.5f})\\n')\n",
    "    \n",
    "    # Re-sampling\n",
    "    X_bal, y_bal = resample_pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_test_evaluation(\n",
    "        method,\n",
    "        metric_dict,\n",
    "        scores,\n",
    "        model,\n",
    "        X_bal, y_bal, X_test, y_test,\n",
    "        train_pipeline=Pipeline(steps=[\n",
    "            ('minmax_scaler', minmax_scaler),\n",
    "        ], verbose=True),\n",
    "        test_pipeline=Pipeline(steps=[\n",
    "            ('standard_scaler', standard_scaler),\n",
    "            ('minmax_scaler', minmax_scaler),\n",
    "        ], verbose=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metric_dict, title):\n",
    "    eval_df  = pd.DataFrame(metric_dict)\n",
    "    eval_df['cv_mean'] = eval_df['cv_score'].apply(np.mean)\n",
    "\n",
    "    metrics  = [x for x in eval_df.columns if x not in ['cv_score', 'method']]\n",
    "    eval_dfs = [eval_df[[x, 'method']].rename(columns={x: 'score'}) for x in metrics]\n",
    "    for i,x in enumerate(eval_dfs):\n",
    "        x['metric'] = metrics[i]\n",
    "\n",
    "    fig = px.bar(\n",
    "        pd.concat(eval_dfs, axis=0),\n",
    "        x='metric',\n",
    "        y='score',\n",
    "        color='method',\n",
    "        barmode='group'\n",
    "    )\n",
    "    fig['layout']['legend_orientation'] = 'h'\n",
    "\n",
    "    vp.generate_plot(\n",
    "        fig,\n",
    "        out_path=OUT_PATH_GRAPH,\n",
    "        out_filename=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metric_dict, 'Phase 5 - Bar - Metrics Comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 6 - Classification\n",
    "- Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_search(X, y, estimator, param_distributions, n_splits=10):\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator,\n",
    "        param_distributions,\n",
    "        scoring='roc_auc',\n",
    "        cv=StratifiedKFold(n_splits=n_splits),\n",
    "        n_jobs=-1,\n",
    "        verbose=10,\n",
    "        n_iter=100,\n",
    "        random_state=0\n",
    "    )\n",
    "    search.fit(X, y)\n",
    "    \n",
    "    return search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weight (Normalize)\n",
    "- Best performance among class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://towardsdatascience.com/logistic-regression-model-tuning-with-scikit-learn-part-1-425142e01af5\n",
    "model  = LogisticRegression(random_state=0, n_jobs=-1,\n",
    "                            class_weight=class_weight(y_train, normalize=True))\n",
    "search = cv_search(\n",
    "    X_train, y_train,\n",
    "    estimator=model,\n",
    "    param_distributions={\n",
    "        'C': np.logspace(-4, 4, 20),\n",
    "        'penalty': ['l2'],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(search.cv_results_)\n",
    "result_df[['params', 'mean_test_score', 'rank_test_score']].sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0, n_jobs=-1,\n",
    "                           class_weight=class_weight(y_train, normalize=True),\n",
    "                           **search.best_params_)\n",
    "\n",
    "# Cross validation\n",
    "scores = cross_validation(\n",
    "    Pipeline(steps=[\n",
    "        ('standard_scaler', standard_scaler),\n",
    "        ('minmax_scaler', minmax_scaler),\n",
    "        ('model', model),\n",
    "    ], verbose=True),\n",
    "    X_train,\n",
    "    y_train\n",
    ")\n",
    "print(f'CV Score: {np.mean(scores) :.5f} ({np.std(scores) :.5f})\\n')\n",
    "\n",
    "# Evaluation\n",
    "train_test_evaluation(\n",
    "    'CV Search (Class Weight)',\n",
    "    metric_dict,\n",
    "    scores,\n",
    "    model,\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    train_pipeline=Pipeline(steps=[\n",
    "        ('standard_scaler', standard_scaler),\n",
    "        ('minmax_scaler', minmax_scaler),\n",
    "    ], verbose=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borderline SMOTE + Tomek\n",
    "- 3rd best performance among re-sampling\n",
    "- Top best performance falls on SVM SMOTE + ENN, and SVM SMOTE + Tomek, but it's too time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "steps  = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('borderline_smote', BorderlineSMOTE(random_state=0, n_jobs=-1)),\n",
    "    ('tomek', TomekLinks(n_jobs=-1, sampling_strategy='all')),\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "    ('model', model),\n",
    "]\n",
    "pipeline = Pipeline(steps, verbose=True)\n",
    "\n",
    "search = cv_search(\n",
    "    X_train, y_train,\n",
    "    estimator=pipeline,\n",
    "    param_distributions={\n",
    "        'model__C': np.logspace(-4, 4, 20),\n",
    "        'model__penalty': ['l2'],\n",
    "    },\n",
    "    n_splits=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(search.cv_results_)\n",
    "result_df[['params', 'mean_test_score', 'rank_test_score']].sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0, n_jobs=-1,\n",
    "                           **{k.replace('model__', ''): v for k,v in search.best_params_.items()})\n",
    "\n",
    "# Cross validation\n",
    "steps = [\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('borderline_smote', BorderlineSMOTE(random_state=0, n_jobs=-1)),\n",
    "    ('tomek', TomekLinks(n_jobs=-1, sampling_strategy='all')),\n",
    "    ('minmax_scaler', minmax_scaler),\n",
    "    ('model', model),\n",
    "]\n",
    "pipeline = Pipeline(steps, verbose=True)\n",
    "\n",
    "# Reference: https://kiwidamien.github.io/how-to-do-cross-validation-when-upsampling-data.html\n",
    "scores = cross_validation(\n",
    "    pipeline,\n",
    "    X_train,\n",
    "    y_train\n",
    ")\n",
    "print(f'CV Score: {np.mean(scores) :.5f} ({np.std(scores) :.5f})\\n')\n",
    "\n",
    "# Re-sampling\n",
    "X_bal, y_bal = Pipeline(steps=[\n",
    "    ('standard_scaler', standard_scaler),\n",
    "    ('borderline_smote', BorderlineSMOTE(random_state=0, n_jobs=-1)),\n",
    "    ('tomek', TomekLinks(n_jobs=-1, sampling_strategy='all')),\n",
    "], verbose=True).fit_resample(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "train_test_evaluation(\n",
    "    'CV Search (Borderline SMOTE + Tomek)',\n",
    "    metric_dict,\n",
    "    scores,\n",
    "    model,\n",
    "    X_bal, y_bal, X_test, y_test,\n",
    "    train_pipeline=Pipeline(steps=[\n",
    "        ('minmax_scaler', minmax_scaler),\n",
    "    ], verbose=True),\n",
    "    test_pipeline=Pipeline(steps=[\n",
    "        ('standard_scaler', standard_scaler),\n",
    "        ('minmax_scaler', minmax_scaler),\n",
    "    ], verbose=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metric_dict, 'Phase 6 - Bar - Metrics Comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 7 - Classification\n",
    "- Model Stacking (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict = {\n",
    "    'macro_precision': [],\n",
    "    'macro_recall':    [],\n",
    "    'macro_f1':        [],\n",
    "    'roc_auc':         [],\n",
    "    'pr_auc':          [],\n",
    "    'cv_score':        [],\n",
    "    'method':          [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_base_models(estimators, X, y):\n",
    "    eval_dict = {\n",
    "        'model':   [],\n",
    "        'score-m': [],\n",
    "        'score-s': []\n",
    "    }\n",
    "\n",
    "    # Cross validation\n",
    "    for k,v in tqdm(estimators):\n",
    "        scores = cross_validation(\n",
    "            Pipeline(steps=[\n",
    "                ('standard_scaler', standard_scaler),\n",
    "                ('minmax_scaler', minmax_scaler),\n",
    "                ('model', v),\n",
    "            ], verbose=True),\n",
    "            X,\n",
    "            y\n",
    "        )\n",
    "        eval_dict['model'].append(k)\n",
    "        eval_dict['score-m'].append(np.mean(scores))\n",
    "        eval_dict['score-s'].append(np.std(scores))\n",
    "    \n",
    "    eval_df = pd.DataFrame(eval_dict).set_index('model')\n",
    "    eval_df['score-m'] = eval_df['score-m'].round(3)\n",
    "    eval_df['score-s'] = eval_df['score-s'].round(3)\n",
    "    eval_df.index.name = ''\n",
    "    \n",
    "    return eval_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = class_weight(y_train, normalize=True)\n",
    "\n",
    "models = [\n",
    "    OneVsRestClassifier(LinearSVC(class_weight=weight_dict, random_state=0), n_jobs=-1),\n",
    "    OneVsRestClassifier(SVC(max_iter=1_000, probability=True, class_weight=weight_dict, random_state=0), n_jobs=-1),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    DummyClassifier(random_state=0),\n",
    "    AdaBoostClassifier(random_state=0),\n",
    "    ExtraTreesClassifier(class_weight=weight_dict, random_state=0, n_jobs=-1),\n",
    "    GradientBoostingClassifier(random_state=0),\n",
    "    RandomForestClassifier(class_weight=weight_dict, random_state=0, n_jobs=-1),\n",
    "    DecisionTreeClassifier(class_weight=weight_dict, random_state=0),\n",
    "    LogisticRegression(class_weight=weight_dict, random_state=0, n_jobs=-1),\n",
    "    PassiveAggressiveClassifier(class_weight=weight_dict, random_state=0, n_jobs=-1),\n",
    "    Perceptron(class_weight=weight_dict, random_state=0, n_jobs=-1),\n",
    "    RidgeClassifier(class_weight=weight_dict, random_state=0),\n",
    "    SGDClassifier(class_weight=weight_dict, random_state=0, n_jobs=-1),\n",
    "    MLPClassifier(random_state=0)\n",
    "]\n",
    "\n",
    "# Final model\n",
    "model = StackingClassifier(\n",
    "    estimators=[\n",
    "        (x.estimator.__class__.__name__ if x.__class__.__name__ == 'OneVsRestClassifier', x)\n",
    "        else (x.__class__.__name__, x)\n",
    "        for x in models\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(class_weight=weight_dict, random_state=0, n_jobs=-1),\n",
    "    cv=StratifiedKFold(10),\n",
    "    n_jobs=-1,\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cross validation (Base Models)\n",
    "eval_df = cv_base_models(model.estimators, X_train, y_train)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation (Meta Model)\n",
    "scores = cross_validation(\n",
    "    Pipeline(steps=[\n",
    "        ('standard_scaler', standard_scaler),\n",
    "        ('minmax_scaler', minmax_scaler),\n",
    "        ('model', model),\n",
    "    ], verbose=True),\n",
    "    X_train,\n",
    "    y_train\n",
    ")\n",
    "print(f'CV Score: {np.mean(scores) :.5f} ({np.std(scores) :.5f})\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "train_test_evaluation(\n",
    "    'Model Stacking (Baseline)',\n",
    "    metric_dict,\n",
    "    scores,\n",
    "    model,\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    train_pipeline=Pipeline(steps=[\n",
    "        ('standard_scaler', standard_scaler),\n",
    "        ('minmax_scaler', minmax_scaler),\n",
    "    ], verbose=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 8 - Classification\n",
    "- Model Stacking (Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
